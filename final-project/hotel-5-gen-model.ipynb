{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import gensim as gs \n",
    "from gensim import corpora, models, similarities\n",
    "import logging\n",
    "import multiprocessing\n",
    "\n",
    "import pickle\n",
    "\n",
    "import gensim\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, make_scorer, recall_score,precision_score,fbeta_score\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# this line tells jupyter notebook to put the plots in the notebook rather than saving them to file.\n",
    "%matplotlib inline\n",
    "\n",
    "# this line makes plots prettier on mac retina screens. If you don't have one it shouldn't do anything.\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotel Reviews: What is real?\n",
    "\n",
    "<h1>Problem Statement</h1>\n",
    "When someone goes on to plan a stay, they tend to use online reviews to base their decision; However, there are usually a range of opinions so how can we tell if a certain review is fake/real or just plain bad luck? Thus the problem statement is to detect fradulent reviews for people are surfing hotel booking sites. \n",
    "\n",
    "<h1>Data Source</h1>\n",
    "1600 Labelled Records, 800 True, 800 Fradulent reviews, plain text review (some generated by MTurk) <br>\n",
    "512k Unlabelled Records, with numerical Ratings, Positive and Negative labels\n",
    "\n",
    "<h1>Prior Research</h1>\n",
    "Using Bi-grams (2-word combinations), detection rate is at ~80% \n",
    "\n",
    "\n",
    "<h1>Proposed Method(s)</h1>\n",
    "-Preprocess the data as according to the best practices (mentioned in Empath, Stanford, 2016) <br>\n",
    "-train_test_split(train, test)We only train our model from the trainsplit corpus. <br> \n",
    "-Decide on which Vocabulary to use (Unlabelled, or with labelled data)[Unlabelled] <br>\n",
    "-Decide on which train data to input into the doc2vec class (unlablled, labelled. [Unlabelled] <br>\n",
    "-Create additional Text Features: <strike>TF-IDF</strike>, <i>unigram and bigram stopword removal (minor improvement)</i>, Probabilistic Context-Free Grammar (but tends to be bad with paras with many sentences), <strike>LIWC (Linguistic tagging-word count features)</strike>Can we replicate the individual features?, GloVE, Consistency,<i> Sentiment-Detection (decent results)</i>, <i>LDA, topic-modelling (marginal improvement)</i>, <i>Empath topic modelling </i><br>\n",
    "-TFIDF good with LDA, LSA <br>\n",
    "-Determine the classifiers to build the model on top of (Logreg, SVM,   GaussianNB , Decision Trees creation), Word Level Features <br>\n",
    "-Consider PCA/K-best? <br>\n",
    "-Determine which semisupervised learning algorithm to implement. there are inbuilt python classes for semisupervised learning (LabelPropagation, LabelSpreading) or self-developed label propagation functions. \n",
    "<br>\n",
    "-Currently, use of other features such as social network topology, or timestamps, or rating behavior will not be examined. \n",
    "\n",
    "<h1>Risks and Assumptions</h1>\n",
    "Risks: There are quite many NLP libraries available (NLTK, gensim, etc.) which means we have to try substanial number of libraries to assess their results.\n",
    "\n",
    "Each run of the algorithm takes up a significant amount of time, thus more time is needed so a CUDA-specific libray (TensorFlow) could be used.However this would mean even more time spent on on-boarding. \n",
    "\n",
    "There is a assumption that there actually exists some pattern or trend that exists in both truthful and fake reviews. \n",
    "\n",
    "<h1>Specific Aim</h1>\n",
    "To aim to obtain between 71% ~ 74% accuracy overall, with a good f1 score: As it is not very useful to customers if there are a lot of false positive, the noise to signal ratio would overwhelm customers who would then fail to accept the system's recommendation of fake review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./input/deceptive-opinion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py36\\lib\\site-packages\\pandas\\core\\generic.py:4619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "truedf = df[df.deceptive=='truthful'].loc[:,'text']\n",
    "fakedf = df[df.deceptive=='deceptive'].loc[:,'text']\n",
    "truedfy = df[df.deceptive=='truthful'].loc[:,'deceptive']\n",
    "fakedfy = df[df.deceptive=='deceptive'].loc[:,'deceptive']\n",
    "truedfy.replace({'truthful':1},inplace=True)\n",
    "fakedfy.replace({'deceptive':0},inplace=True)\n",
    "#Truth = 1, Fake = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_corpus = pickle.load(open('./input/unlabelled_corpus_clean2.p','rb'))\n",
    "true_corpus = pickle.load(open('./input/true_corpus_clean2.p','rb'))\n",
    "fake_corpus = pickle.load(open('./input/fake_corpus_clean2.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_arr = []\n",
    "ctr = 0\n",
    "for ind, s in enumerate(unlabelled_corpus):\n",
    "    temp_arr.append(gensim.models.doc2vec.TaggedDocument(s,[ctr]))\n",
    "    ctr += 1\n",
    "unlabelled_corpus = temp_arr.copy()\n",
    "temp_arr = []\n",
    "for ind, s in enumerate(true_corpus):\n",
    "    temp_arr.append(gensim.models.doc2vec.TaggedDocument(s,[ctr]))\n",
    "    ctr += 1\n",
    "true_corpus = temp_arr.copy()\n",
    "temp_arr = []\n",
    "for ind, s in enumerate(fake_corpus):\n",
    "    temp_arr.append(gensim.models.doc2vec.TaggedDocument(s,[ctr]))\n",
    "    ctr += 1\n",
    "fake_corpus = temp_arr.copy()\n",
    "del(temp_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_index = list(range(len(unlabelled_corpus)))\n",
    "np.random.shuffle(unlabelled_index)\n",
    "kratio = 3\n",
    "rand_unlabelled_corpus = [unlabelled_corpus[a] for a in unlabelled_index[:(len(true_corpus) + len(fake_corpus))*kratio]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "turk_model = gensim.models.doc2vec.Doc2Vec(dm=0, size=100,min_count=30, window=5,workers=cores, seed=8, negative=5)\n",
    "turk_model.build_vocab(unlabelled_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27200977"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turk_model.train(unlabelled_corpus, total_examples=turk_model.corpus_count, epochs=turk_model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vec = pd.DataFrame([turk_model.infer_vector(s.words) for s in true_corpus])\n",
    "fake_vec = pd.DataFrame([turk_model.infer_vector(s.words) for s in fake_corpus])\n",
    "# rand_unlabelled_vec = pd.DataFrame([turk_model.infer_vector(s.words) for s in rand_unlabelled_corpus])\n",
    "unlabelled_vec = pd.DataFrame([turk_model.infer_vector(s.words) for s in unlabelled_corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# rand_unlabelled_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(unlabelled_vec, open('./input/unlabelled_vec.p','wb'))\n",
    "# pickle.dump(true_vec, open('./input/true_vec.p','wb'))\n",
    "# pickle.dump(fake_vec, open('./input/fake_vec.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_vec = pickle.load(open('./input/true_vec.p','rb'))\n",
    "# fake_vec = pickle.load(open('./input/fake_vec.p','rb'))\n",
    "# unlabelled_vec = pickle.load(open('./input/unlabelled_vec.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER VECS\n",
    "true_vader_vec = pickle.load(open('./input/true_vader_raw_vec.p','rb'))\n",
    "fake_vader_vec = pickle.load(open('./input/fake_vader_raw_vec.p','rb'))\n",
    "vader_vec = pd.concat([true_vader_vec, fake_vader_vec], axis = 0)\n",
    "# unlabelled_vader_vec = pickle.load(open('./input/unlabelled_vader_vec.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA VECS\n",
    "true_lda_vec = pickle.load(open('./input/true_lda_vec.p','rb'))\n",
    "fake_lda_vec = pickle.load(open('./input/fake_lda_vec.p','rb'))\n",
    "lda_vec = pd.concat([true_lda_vec, fake_lda_vec], axis = 0)\n",
    "# unlabelled_lda_vec = pickle.load(open('./input/unlabelled_lda_vec.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMP VEC\n",
    "true_emp_vec = pickle.load(open('./input/true_empraw_vec.p','rb'))\n",
    "fake_emp_vec = pickle.load(open('./input/fake_empraw_vec.p','rb'))\n",
    "emp_vec = pd.concat([true_emp_vec, fake_emp_vec], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "true_fake_vec = pd.concat([true_vec, fake_vec], axis=0)\n",
    "true_fake_vec2 = pd.concat([true_fake_vec, vader_vec, lda_vec, emp_vec], axis=1)\n",
    "all_y = pd.concat([truedfy, fakedfy], axis= 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(true_fake_vec2, all_y, train_size=0.75, random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform baseline Supervised Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_report(y, y_pred, model):\n",
    "    conmat = confusion_matrix(y, y_pred, labels=model.classes_)\n",
    "    # converts np.matrix format matrix to a dataframe and adds index and column names\n",
    "    conmat= pd.DataFrame(conmat, columns=model.classes_, index=model.classes_)\n",
    "    print(conmat)\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def run_test(X, y, cv_val, scoring):\n",
    "    gnb = GaussianNB()\n",
    "    dtree = DecisionTreeClassifier()\n",
    "    svm2 = svm.SVC(random_state=8)\n",
    "    xg = XGBClassifier()\n",
    "    # logreg_cv = linear_model.LogisticRegressionCV(Cs=100, cv=5, penalty='l1',scoring='accuracy',solver='liblinear',n_jobs=-1)\n",
    "    print('Gaussian NB:')\n",
    "    scorelist = cross_val_score(gnb, X, y, cv=cv_val, scoring=scoring,n_jobs=-1)\n",
    "    print(scorelist, np.mean(scorelist))\n",
    "    print('DecisionTree')\n",
    "    scorelist = cross_val_score(dtree, X, y, cv=cv_val, scoring=scoring,n_jobs=-1)\n",
    "    print(scorelist, np.mean(scorelist))\n",
    "    print('SVM:')\n",
    "    scorelist = cross_val_score(svm2, X, y, cv=cv_val, scoring=scoring,n_jobs=-1)\n",
    "    print(scorelist, np.mean(scorelist))\n",
    "    print('XGB Default:')\n",
    "    scorelist = cross_val_score(xg, X, y, cv=cv_val, scoring=scoring,n_jobs=-1)\n",
    "    print(scorelist, np.mean(scorelist))\n",
    "    # print('Logistics Regression:')\n",
    "    # scorelist = cross_val_score(logreg_cv, X_train, y_train, cv=5, scoring='f1', n_jobs=-1)\n",
    "    # print(scorelist, np.mean(scorelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB:\n",
      "[0.63436123 0.61111111 0.68070175 0.52307692 0.62831858] 0.6155139212249944\n",
      "DecisionTree\n",
      "[0.50220264 0.592      0.58823529 0.60408163 0.63529412] 0.5843627375179147\n",
      "SVM:\n",
      "[0.77911647 0.71489362 0.70866142 0.72268908 0.72961373] 0.7309948619486794\n",
      "XGB Default:\n",
      "[0.68695652 0.65271967 0.67489712 0.67521368 0.70119522] 0.6781964401379683\n"
     ]
    }
   ],
   "source": [
    "run_test(X_train, y_train, 5, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.15,\n",
      "       gamma=0.6, learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=9, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xg_clf = XGBClassifier()\n",
    "xg_params = {\n",
    "#     'booster'=['gbtree'],\n",
    "    'colsample_bytree':[0.15,0.4,0.85],\n",
    "    'max_depth':[4,8,16,20],\n",
    "    'subsample':[0.7,0.95],\n",
    "    'min_child_weight':[1,3,9],\n",
    "    'gamma':[0,0.01,0.05,0.3,0.6,1]\n",
    "}\n",
    "scorer = make_scorer(fbeta_score,beta=0.5)\n",
    "xg_gs = GridSearchCV(xg_clf, xg_params, cv=5, scoring=scorer, n_jobs=-1)\n",
    "xg_gs.fit(X_train,y_train)\n",
    "best_xg_clf = xg_gs.best_estimator_\n",
    "print(best_xg_clf)\n",
    "best_pred = best_xg_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.685, 'recall': 0.6966292134831461, 'precision': 0.6326530612244898}\n"
     ]
    }
   ],
   "source": [
    "performance = {'accuracy': accuracy_score(best_pred,y_test),\n",
    "                'recall': recall_score(best_pred,y_test),\n",
    "                'precision': precision_score(best_pred,y_test)}\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=8, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "svm_clf = svm.SVC(random_state=8)\n",
    "svm_params = {\n",
    "    \"kernel\":['rbf','linear'],\n",
    "    'C':[0.1,0.2,0.4,0.6,0.8,1,10],\n",
    "    'gamma': np.logspace(-1,1,9)\n",
    "}\n",
    "scorer = make_scorer(fbeta_score,beta=0.5)\n",
    "svm_gs = GridSearchCV(svm_clf, svm_params, cv=5, scoring=scorer, n_jobs=-1)\n",
    "svm_gs.fit(X_train,y_train)\n",
    "best_clf = svm_gs.best_estimator_\n",
    "print(best_clf)\n",
    "best_pred = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.705, 'recall': 0.695, 'precision': 0.7091836734693877}\n"
     ]
    }
   ],
   "source": [
    "performance = {'accuracy': accuracy_score(best_pred,y_test),\n",
    "                'recall': recall_score(best_pred,y_test),\n",
    "                'precision': precision_score(best_pred,y_test)}\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of Semi-Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "0  137   67\n",
      "1   65  131\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.67      0.67       204\n",
      "          1       0.66      0.67      0.66       196\n",
      "\n",
      "avg / total       0.67      0.67      0.67       400\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 1 columns):\n",
      "0    6000 non-null int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 47.0 KB\n"
     ]
    }
   ],
   "source": [
    "# we pseudo label a bunch of unlabelled data\n",
    "\n",
    "def pseudo_label(trained_model, labelled_X, labelled_y, unlabelled, sample_rate):\n",
    "    unlabelled_index = list(range(len(unlabelled)))\n",
    "    np.random.shuffle(unlabelled_index)\n",
    "    end_index = int(sample_rate * float(len(unlabelled)))\n",
    "    rand_unlabelled = pd.DataFrame([unlabelled.iloc[a,:] for a in unlabelled_index[:end_index]]).copy()\n",
    "#     rand_unlabelled.reset_index(inplace=True,drop=True)\n",
    "#     print(rand_unlabelled.head(10))\n",
    "    all_data = pd.concat([labelled_X, rand_unlabelled], axis=0, ignore_index=True)\n",
    "    p_labels = pd.DataFrame(trained_model.predict(rand_unlabelled))\n",
    "    all_labels = pd.concat([labelled_y, p_labels], axis=0, ignore_index=True)\n",
    "    \n",
    "    trained_model.fit(all_data, all_labels)\n",
    "    return trained_model, all_data , all_labels\n",
    "#SMOTE BOOST\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "newlr, newX_train, newy_train = pseudo_label(logreg_cv, X_train, y_train, rand_unlabelled_vec, 1.0)\n",
    "y_lr_pred = newlr.predict(X_test)\n",
    "summary_report(y_test, y_lr_pred, newlr)\n",
    "newy_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1\n",
      "0  118  86\n",
      "1  118  78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.58      0.54       204\n",
      "          1       0.48      0.40      0.43       196\n",
      "\n",
      "avg / total       0.49      0.49      0.49       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "from scipy import sparse as sp\n",
    "\n",
    "newX_train = pd.concat([X_train, rand_unlabelled_vec],axis=0)\n",
    "newy_train = pd.concat([y_train, pd.Series([-1] *rand_unlabelled_vec.shape[0])],axis=0)\n",
    "# newX_train_spread = newX_train.copy()\n",
    "# newy_train_spread = newy_train.copy()\n",
    "\n",
    "pseudo_params = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma' : range(10,100,10)\n",
    "}\n",
    "label_prop_gridsearch = GridSearchCV(LabelPropagation(), pseudo_params, n_jobs=-1)\n",
    "# label_spread_gridsearch = GridSearchCV(LabelSpreading(), pseudo_params)\n",
    "label_prop_gridsearch.fit(newX_train, newy_train)\n",
    "# label_spread_gridsearch.fit(newX_train_spread, newy_train_spread)\n",
    "\n",
    "y_prop_grid_pred = label_prop_gridsearch.best_estimator_.predict(X_test)\n",
    "# y_spread_grid_pred = label_spread_gridsearch.best_estimator_.predict(X_test)\n",
    "summary_report(y_test, y_prop_grid_pred, label_prop_gridsearch.best_estimator_)\n",
    "# summary_report(y_test, y_spread_grid_pred, label_spread_gridsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo_params2 = {\n",
    "#     'kernel': ['knn'],\n",
    "#     'alpha' : np.linspace(0.01,0.99,20)\n",
    "# }\n",
    "# label_prop_gridsearch = GridSearchCV(LabelPropagation(), pseudo_params2)\n",
    "# label_spread_gridsearch = GridSearchCV(LabelSpreading(), pseudo_params2)\n",
    "# label_prop_gridsearch.fit(newX_train, newy_train)\n",
    "# label_spread_gridsearch.fit(newX_train_spread, newy_train_spread)\n",
    "\n",
    "# y_prop_grid_pred = label_prop_gridsearch.best_estimator_.predict(X_test)\n",
    "# y_spread_grid_pred = label_spread_gridsearch.best_estimator_.predict(X_test)\n",
    "# summary_report(y_test, y_prop_grid_pred, label_prop_gridsearch.best_estimator_)\n",
    "# summary_report(y_test, y_spread_grid_pred, label_spread_gridsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label_prop_model = LabelPropagation(kernel='rbf',gamma=10,n_jobs=-1)\n",
    "# # label_spread_model = LabelSpreading(kernel='rbf',gamma=10,n_jobs=-1)\n",
    "# # label_prop_model.fit(newX_train, newy_train)\n",
    "# # label_spread_model.fit(newX_train_spread, newy_train_spread)\n",
    "# y_prop_pred = label_prop_model.predict(X_test)\n",
    "# y_spread_pred = label_spread_model.predict(X_test)\n",
    "\n",
    "# summary_report(y_test, y_prop_pred, label_prop_model)\n",
    "# summary_report(y_test, y_spread_pred, label_spread_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
