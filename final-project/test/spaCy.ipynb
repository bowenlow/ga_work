{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import gensim as gs \n",
    "from gensim import corpora, models, similarities\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,make_scorer, recall_score,precision_score,fbeta_score\n",
    "\n",
    "import gensim,logging\n",
    "from gensim.parsing import PorterStemmer\n",
    "from gensim.models import Word2Vec, Doc2Vec, Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from wikipedia import search,page\n",
    "import multiprocessing\n",
    "import collections\n",
    "import re\n",
    "import warnings\n",
    "import spacy\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1\n",
    "\n",
    "np.random.seed(0)\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/deceptive-opinion.csv')\n",
    "\n",
    "stop_words = pd.read_csv('../input/stopwords.csv',names=['stop'])\n",
    "new_stop = stop_words.stop.map(lambda x: str.capitalize(x))\n",
    "all_stop_set = set(stop_words.stop.append(new_stop,ignore_index=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate combinations of all_stop_words, bigrams\n",
    "#generate bigram\n",
    "bigram_stops=[]\n",
    "for a in all_stop_set:\n",
    "    for b in all_stop_set:\n",
    "        bigram_stop = a+\"_\"+b\n",
    "        bigram_stops.append(bigram_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stop_set = all_stop_set.union(bigram_stops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(sentdf, tokens_only=False):\n",
    "    for i, line in enumerate(sentdf):\n",
    "        if tokens_only:\n",
    "            yield list(gensim.utils.tokenize(line))\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(list(gensim.utils.tokenize(line)),[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "truedf = df[df.deceptive=='truthful'].loc[:,'text']\n",
    "fakedf = df[df.deceptive=='deceptive'].loc[:,'text']\n",
    "truedfy = df[df.deceptive=='truthful'].loc[:,'deceptive']\n",
    "fakedfy = df[df.deceptive=='deceptive'].loc[:,'deceptive']\n",
    "truedfy.replace({'truthful':1},inplace=True)\n",
    "fakedfy.replace({'deceptive':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I stayed at The Talbott for 3 nights on business and was very pleased. The staff was friendly as can be immediately confirming the lore of the midwest. I was upgraded to a suite which was bigger than my apartment and certainly more luxurious. The free wi-fi came in handy as I needed to work remotely while there. Everything from the comfort of the bed to the staff and location made this a great stay. Oh, and I got to workout at the huge Equinox right next door for free. \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truedf.iloc[189]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# prefix_re = re.compile(r'''^[\\[\\(\"']''')\n",
    "# suffix_re = re.compile(r'''[\\]\\)\"']$''')\n",
    "# infix_re = re.compile(r'''[-~]''')\n",
    "# simple_url_re = re.compile(r'''^https?://''')\n",
    "\n",
    "# nlp.tokenizer = Tokenizer(nlp.vocab, \n",
    "#                           prefix_search = prefix_re.search,\n",
    "#                           suffix_search = suffix_re.search,\n",
    "#                           infix_finditer = infix_re.finditer,\n",
    "#                           token_match = simple_url_re.match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "true_corpus = list(read_corpus(truedf,tokens_only=True))\n",
    "fake_corpus = list(read_corpus(fakedf,tokens_only=True))\n",
    "def to_list(doc):\n",
    "    return [t.text for t in doc]\n",
    "# true_corpus = [to_list(nlp(s))[:-1] for ind,s in enumerate(truedf)]\n",
    "# fake_corpus = [to_list(nlp(s))[:-1] for ind,s in enumerate(fakedf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:40:58,204 : INFO : collecting all words and their counts\n",
      "2018-02-05 13:40:58,206 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2018-02-05 13:40:58,567 : INFO : collected 96727 word types from a corpus of 239406 words (unigram + bigrams) and 1600 sentences\n",
      "2018-02-05 13:40:58,568 : INFO : using 96727 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "2018-02-05 13:40:58,570 : INFO : source_vocab length 96727\n",
      "2018-02-05 13:40:59,415 : INFO : Phraser built with 828 828 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "phrase_list = []\n",
    "\n",
    "sentence_stream = [s for s in true_corpus + fake_corpus]\n",
    "phrases = Phrases(sentence_stream)\n",
    "bigram = Phraser(phrases)\n",
    "sentence_stream = [bigram[s] for s in sentence_stream]\n",
    "true_corpus = [bigram[s] for s in true_corpus]\n",
    "fake_corpus = [bigram[s] for s in fake_corpus]\n",
    "\n",
    "# phrases = Phrases(sentence_stream)\n",
    "# trigram = Phraser(phrases)\n",
    "# sentence_stream = [trigram[s] for s in sentence_stream]\n",
    "# true_corpus = [trigram[s] for s in true_corpus]\n",
    "# fake_corpus = [trigram[s] for s in fake_corpus]\n",
    "\n",
    "def filter_stream(df, stopword_set):\n",
    "    sentence_stream = []\n",
    "    for s in df:\n",
    "        s2 = [c  for c in s if c not in stopword_set] \n",
    "        sentence_stream.append(s2)\n",
    "    return sentence_stream\n",
    "\n",
    "# sentence_stream2 = []\n",
    "# for s in sentence_stream:\n",
    "#     s2 = [c  for c in s if c not in all_stop_set] \n",
    "#     sentence_stream2.append(s2)\n",
    "\n",
    "sentence_stream2 = filter_stream(sentence_stream, all_stop_set)\n",
    "true_corpus = filter_stream(true_corpus, all_stop_set)\n",
    "fake_corpus = filter_stream(fake_corpus, all_stop_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trigram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3393413ba059>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnot_seen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbigram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphrasegrams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrigram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphrasegrams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mnot_seen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrigram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphrasegrams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trigram' is not defined"
     ]
    }
   ],
   "source": [
    "# not_seen = set()\n",
    "# for a in bigram.phrasegrams.keys():\n",
    "#     if a not in trigram.phrasegrams.keys():\n",
    "#         not_seen.add(a)\n",
    "# for a in trigram.phrasegrams.keys():\n",
    "#     if a not in bigram.phrasegrams.keys():\n",
    "#         not_seen.add(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(bigram, open('../input/plain_bigram.p','wb'))\n",
    "# pickle.dump(trigram, open('../input/plain_trigram.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_corpus_raw = pickle.load(open('../input/true_corpus_raw.p','rb'))\n",
    "fake_corpus_raw = pickle.load(open('../input/fake_corpus_raw.p','rb'))\n",
    "sentence_stream_raw = true_corpus_raw + fake_corpus_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "compound = []\n",
    "neg = []\n",
    "neu = []\n",
    "pos = []\n",
    "# raw_corpus = true_corpus + fake_corpus\n",
    "for s in sentence_stream_raw:\n",
    "    sent = sia.polarity_scores(' '.join(s))\n",
    "    compound.append(sent['compound'])\n",
    "    neg.append(sent['neg'])\n",
    "    neu.append(sent['neu'])\n",
    "    pos.append(sent['pos'])\n",
    "\n",
    "vader_sent = pd.DataFrame({'compound':compound, 'neg':neg, 'neu':neu, 'pos':pos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "from empath import Empath\n",
    "lexicon = Empath()\n",
    "\n",
    "lexicon_results = pd.DataFrame(columns=lexicon.cats)\n",
    "for ind, s in enumerate(sentence_stream_raw):\n",
    "    lexicon_results = lexicon_results.append(pd.Series([np.nan]), ignore_index=True)\n",
    "    results = (lexicon.analyze(s))\n",
    "    if (ind % 100 == 0):\n",
    "        print(ind)\n",
    "    for k in results.keys():\n",
    "        lexicon_results[k].iloc[ind] = results[k]\n",
    "\n",
    "lexicon_results.drop(columns=[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>help</th>\n",
       "      <th>office</th>\n",
       "      <th>dance</th>\n",
       "      <th>money</th>\n",
       "      <th>wedding</th>\n",
       "      <th>domestic_work</th>\n",
       "      <th>sleep</th>\n",
       "      <th>medical_emergency</th>\n",
       "      <th>cold</th>\n",
       "      <th>hate</th>\n",
       "      <th>...</th>\n",
       "      <th>weapon</th>\n",
       "      <th>children</th>\n",
       "      <th>monster</th>\n",
       "      <th>ocean</th>\n",
       "      <th>giving</th>\n",
       "      <th>contentment</th>\n",
       "      <th>writing</th>\n",
       "      <th>rural</th>\n",
       "      <th>positive_emotion</th>\n",
       "      <th>musical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   help  office  dance  money  wedding  domestic_work  sleep  \\\n",
       "0   1.0     1.0    0.0    2.0      1.0            3.0    1.0   \n",
       "1   0.0     2.0    0.0    0.0      0.0            0.0    1.0   \n",
       "2   2.0     0.0    0.0    1.0      1.0            2.0    4.0   \n",
       "3   1.0     5.0    0.0    1.0      0.0            0.0    0.0   \n",
       "4   0.0     1.0    0.0    0.0      0.0            1.0    0.0   \n",
       "5   1.0     5.0    0.0    0.0      0.0            2.0    3.0   \n",
       "6   2.0     4.0    1.0    0.0      0.0            1.0    2.0   \n",
       "\n",
       "   medical_emergency  cold  hate   ...     weapon  children  monster  ocean  \\\n",
       "0                0.0   0.0   0.0   ...        0.0       1.0      0.0    1.0   \n",
       "1                0.0   0.0   0.0   ...        0.0       0.0      0.0    0.0   \n",
       "2                0.0   0.0   0.0   ...        0.0       2.0      0.0    0.0   \n",
       "3                0.0   1.0   0.0   ...        0.0       0.0      0.0    0.0   \n",
       "4                0.0   0.0   0.0   ...        0.0       0.0      0.0    0.0   \n",
       "5                0.0   2.0   0.0   ...        0.0       0.0      0.0    0.0   \n",
       "6                0.0   0.0   0.0   ...        0.0       0.0      0.0    0.0   \n",
       "\n",
       "   giving  contentment  writing  rural  positive_emotion  musical  \n",
       "0     2.0          0.0      0.0    0.0               1.0      0.0  \n",
       "1     0.0          0.0      0.0    0.0               1.0      0.0  \n",
       "2     0.0          0.0      0.0    0.0               3.0      0.0  \n",
       "3     0.0          1.0      0.0    1.0               1.0      0.0  \n",
       "4     3.0          0.0      1.0    0.0               1.0      0.0  \n",
       "5     1.0          0.0      0.0    0.0               2.0      0.0  \n",
       "6     2.0          0.0      0.0    0.0               0.0      1.0  \n",
       "\n",
       "[7 rows x 194 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_results.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_fake_corpus = []\n",
    "for ind,s in enumerate(sentence_stream2):\n",
    "    true_fake_corpus.append(gensim.models.doc2vec.TaggedDocument(s,[ind]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:44:59,217 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-02-05 13:44:59,337 : INFO : built Dictionary(11389 unique tokens: ['We_stayed', 'one_night', 'getaway', 'family', 'thursday']...) from 1600 documents (total 111597 corpus positions)\n",
      "2018-02-05 13:44:59,422 : INFO : collecting document frequencies\n",
      "2018-02-05 13:44:59,423 : INFO : PROGRESS: processing document #0\n",
      "2018-02-05 13:44:59,442 : INFO : calculating IDF weights for 1600 documents and 11388 features (98942 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "# true_raw = pickle.load(open('../input/true_corpus_raw.p','rb'))\n",
    "# fake_raw = pickle.load(open('../input/fake_corpus_raw.p','rb'))\n",
    "\n",
    "dictionary = corpora.Dictionary(sentence_stream2)\n",
    "\n",
    "corpus_bow = [dictionary.doc2bow(s) for s in sentence_stream2]\n",
    "tfidf = models.TfidfModel(corpus_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:44:59,456 : INFO : using autotuned alpha, starting with [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
      "2018-02-05 13:44:59,460 : INFO : using serial LDA version on this node\n",
      "2018-02-05 13:45:03,855 : INFO : running online (multi-pass) LDA training, 100 topics, 5 passes over the supplied corpus of 1600 documents, updating model once every 400 documents, evaluating perplexity every 1600 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2018-02-05 13:45:03,857 : INFO : PROGRESS: pass 0, at document #400/1600\n",
      "2018-02-05 13:45:05,234 : INFO : optimized alpha [0.009875284344547512, 0.009775814771369138, 0.009929218519022632, 0.009594226016146866, 0.00990000266775622, 0.009929390448404967, 0.009646167907507011, 0.009853640130976223, 0.00995486372710864, 0.009922575209475837, 0.009881172548183418, 0.00974898492508444, 0.010029581387595219, 0.009829076203019099, 0.009851488932560737, 0.009697213149025727, 0.0096459803920161, 0.009723193319411828, 0.009851273180120735, 0.010033633239033939, 0.010085260707603906, 0.009592551193584178, 0.009853485945339292, 0.009981785714484616, 0.009774978690595897, 0.0097233348964896, 0.009983216214289919, 0.009826101007696852, 0.00995570291883599, 0.009825421620636723, 0.009800041124618476, 0.009826524696341085, 0.009826038463485476, 0.009722270752976003, 0.00969672162381519, 0.009619587406893733, 0.010057583507557578, 0.009670460516257147, 0.009664445231064094, 0.010137556902901124, 0.009775082550064767, 0.009747971987647848, 0.00967032500657996, 0.009594299610941697, 0.009978316444721875, 0.00959389302722766, 0.009672254791060113, 0.009819453354461386, 0.0099824623547998, 0.00974702013401182, 0.00995536641358551, 0.009957498228633916, 0.009851555024028449, 0.0096978553697767, 0.010007794253470745, 0.010186115853462095, 0.009612258860020626, 0.009618025292466924, 0.009671381239520596, 0.009721791821986094, 0.009877383661039619, 0.009827597076847076, 0.009955385636032182, 0.009765443030680328, 0.00959350998784954, 0.010256903260059163, 0.010030780218374565, 0.009851512567906463, 0.009981274526542459, 0.010266706387436925, 0.009773918413769688, 0.00987797386969592, 0.009826096017758579, 0.009749284390542502, 0.009722193503202664, 0.009672438880266962, 0.009798220479958705, 0.00972230818098913, 0.009691914547376845, 0.009669799878050897, 0.009936976482894318, 0.009926538842559533, 0.009645523293510063, 0.009800228803010444, 0.00961845218521062, 0.00995362728716321, 0.010369559846945068, 0.009672385829610563, 0.009960719053665593, 0.009876539316237234, 0.009697994803528428, 0.009774873136525673, 0.009746938224015457, 0.009954739839839093, 0.009799152591431482, 0.009756254504752983, 0.010212630082921554, 0.0097723854663885, 0.009926446917567493, 0.009619619684051436]\n",
      "2018-02-05 13:45:05,251 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:05,512 : INFO : topic #57 (0.010): 0.021*\"well\" + 0.021*\"clean\" + 0.015*\"near\" + 0.015*\"comfortable\" + 0.015*\"many\" + 0.015*\"Free\" + 0.015*\"continental_breakfast\" + 0.015*\"staffed\" + 0.015*\"located\" + 0.015*\"evening\"\n",
      "2018-02-05 13:45:05,515 : INFO : topic #21 (0.010): 0.010*\"liked\" + 0.007*\"a_bit\" + 0.007*\"bar\" + 0.006*\"will\" + 0.005*\"really\" + 0.005*\"place\" + 0.004*\"friendly\" + 0.004*\"lovely\" + 0.004*\"rooms\" + 0.004*\"space\"\n",
      "2018-02-05 13:45:05,519 : INFO : topic #65 (0.010): 0.022*\"hotel\" + 0.017*\"great\" + 0.016*\"room\" + 0.009*\"staff\" + 0.009*\"Chicago\" + 0.008*\"s\" + 0.007*\"lobby\" + 0.007*\"go\" + 0.006*\"rate\" + 0.006*\"service\"\n",
      "2018-02-05 13:45:05,523 : INFO : topic #69 (0.010): 0.027*\"hotel\" + 0.020*\"room\" + 0.012*\"great\" + 0.009*\"Chicago\" + 0.008*\"staff\" + 0.008*\"stay\" + 0.007*\"this_hotel\" + 0.007*\"Hotel\" + 0.007*\"us\" + 0.006*\"bed\"\n",
      "2018-02-05 13:45:05,526 : INFO : topic #86 (0.010): 0.029*\"hotel\" + 0.015*\"great\" + 0.011*\"room\" + 0.011*\"s\" + 0.008*\"good\" + 0.007*\"Chicago\" + 0.007*\"one\" + 0.007*\"stay\" + 0.006*\"nice\" + 0.006*\"staff\"\n",
      "2018-02-05 13:45:05,536 : INFO : topic diff=92.864903, rho=1.000000\n",
      "2018-02-05 13:45:05,640 : INFO : PROGRESS: pass 0, at document #800/1600\n",
      "2018-02-05 13:45:07,014 : INFO : optimized alpha [0.01061686056700944, 0.010685840485895397, 0.010491578648853157, 0.009734809461145591, 0.010745677310484257, 0.010562240860970462, 0.009888537303741339, 0.010824417411868324, 0.011003672542493702, 0.010433088611257258, 0.011243685447607238, 0.010410693140086483, 0.010887333174143497, 0.011242500397866747, 0.010408787895625285, 0.010041613130032273, 0.01051253802389765, 0.010101524450860877, 0.01014361249131608, 0.011329085761156689, 0.011199709200993913, 0.009455164460950577, 0.010986299053277436, 0.010221574301224312, 0.010280111986519305, 0.009753230143999113, 0.011651848286681775, 0.010436823616559112, 0.010536959321438109, 0.010350527130337675, 0.010978646739807274, 0.010103330170275036, 0.010539268870802565, 0.010154731344494872, 0.009814569569961058, 0.0100340253844421, 0.01152426626677581, 0.00945895985886537, 0.0095067208098881, 0.011627515764418776, 0.010352775743601385, 0.009637400131300752, 0.010622317176078155, 0.010131528578859158, 0.010454128624171652, 0.009544614114242197, 0.010293468734001356, 0.010766756111519789, 0.01128633162968997, 0.010074642784722638, 0.010842039408973238, 0.01057470720888515, 0.010162648584338746, 0.0103046733193181, 0.010989588422171254, 0.01094334767859581, 0.010217920642923326, 0.009792055596245302, 0.009720655371117373, 0.009855429081328868, 0.011261622989971949, 0.010103874657650294, 0.011112497108313557, 0.010520470020235194, 0.010673153262187924, 0.011030535576407253, 0.010489251544837703, 0.01014558583738502, 0.010400929571554371, 0.011824045393504123, 0.00987534122182884, 0.01045800397567221, 0.011195857308068592, 0.010234139010896069, 0.009875872654717165, 0.010261087756708621, 0.010444600842587507, 0.010381341398846831, 0.00989781942316597, 0.0107102630140933, 0.009943443397626608, 0.010591820849833063, 0.009850795391243717, 0.010111596147154135, 0.010848270704076743, 0.010412589012476364, 0.01182737917446433, 0.010225741413479577, 0.010200939851303523, 0.010293248652584486, 0.009415818120319459, 0.0098221634362143, 0.01000581163735974, 0.010516020301475713, 0.010785174328213758, 0.011070518119542358, 0.011304163042645955, 0.011158672508632396, 0.010292147068252974, 0.009602423233819185]\n",
      "2018-02-05 13:45:07,030 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:07,252 : INFO : topic #90 (0.009): 0.014*\"door\" + 0.014*\"treated\" + 0.014*\"hotel\" + 0.013*\"whether\" + 0.013*\"run\" + 0.008*\"looking_for\" + 0.008*\"stay\" + 0.007*\"quickly\" + 0.007*\"right\" + 0.005*\"great\"\n",
      "2018-02-05 13:45:07,254 : INFO : topic #21 (0.009): 0.013*\"either\" + 0.013*\"company\" + 0.012*\"Monoco\" + 0.011*\"liked\" + 0.009*\"lack_of\" + 0.009*\"memorabilia\" + 0.009*\"pretentious\" + 0.008*\"fiance\" + 0.007*\"full_price\" + 0.007*\"disappointment\"\n",
      "2018-02-05 13:45:07,256 : INFO : topic #26 (0.012): 0.029*\"room\" + 0.016*\"bathroom\" + 0.015*\"hotel\" + 0.012*\"cold\" + 0.010*\"I_guess\" + 0.009*\"shower\" + 0.009*\"get\" + 0.009*\"put\" + 0.009*\"said\" + 0.009*\"bed\"\n",
      "2018-02-05 13:45:07,259 : INFO : topic #69 (0.012): 0.027*\"hotel\" + 0.024*\"room\" + 0.015*\"uncomfortable\" + 0.013*\"credit\" + 0.010*\"gave_me\" + 0.009*\"small\" + 0.008*\"bed\" + 0.007*\"just\" + 0.007*\"Chicago\" + 0.007*\"NO\"\n",
      "2018-02-05 13:45:07,262 : INFO : topic #86 (0.012): 0.029*\"hotel\" + 0.013*\"room\" + 0.013*\"s\" + 0.012*\"one\" + 0.009*\"requests\" + 0.008*\"service\" + 0.008*\"fan\" + 0.007*\"finally\" + 0.007*\"good\" + 0.007*\"break\"\n",
      "2018-02-05 13:45:07,276 : INFO : topic diff=9.885478, rho=0.707107\n",
      "2018-02-05 13:45:07,372 : INFO : PROGRESS: pass 0, at document #1200/1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:45:08,292 : INFO : optimized alpha [0.01104410040985386, 0.010952229960695038, 0.011176264640096545, 0.010082435529413734, 0.011697526725979722, 0.012220447617177659, 0.010430507526481203, 0.011382527371687857, 0.011500930675323632, 0.011098972043608907, 0.012975755850271149, 0.011547993000990282, 0.011494777079479887, 0.012235249277467462, 0.010676377970724916, 0.010484673595984208, 0.010657090975561686, 0.010101866114515022, 0.010606970850205838, 0.011917136412570634, 0.012113512534759768, 0.009469694966596331, 0.01177208571868786, 0.010489275070019715, 0.010457208719901037, 0.010205089315042134, 0.012623136465648572, 0.010950558945589996, 0.011491822831224427, 0.010878543646326106, 0.011342070141697042, 0.01061002945761004, 0.011069560335278745, 0.010168554305984307, 0.009849375368215434, 0.010801055757773712, 0.012682809715985044, 0.009516617354292004, 0.009785036524876634, 0.01201925325992097, 0.01088233820199688, 0.009507491767516762, 0.010702742131316981, 0.010233686131735318, 0.010493404661343726, 0.009681031022806303, 0.01099725474715167, 0.01120434013645591, 0.01322995085774412, 0.010504500332346988, 0.011429986401376066, 0.011061285981652331, 0.010504869909022904, 0.010875643717129124, 0.012506147073037604, 0.011261221361048858, 0.010872602703078108, 0.010227098740362482, 0.009871326775907564, 0.010148799709163743, 0.011630672699635285, 0.010581335960576586, 0.01153016195221463, 0.010633740767470649, 0.011668478123262166, 0.011704668111793477, 0.011362587780224472, 0.010383853524790067, 0.011096072045040825, 0.01265195718601217, 0.009953350547968585, 0.010957748063495053, 0.011463343784003424, 0.010275563943530498, 0.009895357231556129, 0.010483878769594212, 0.01088121556708591, 0.010847639125061133, 0.010423321101860953, 0.011165295357154282, 0.010709888186163067, 0.011247972584949547, 0.010001114888958985, 0.010259960895318264, 0.01294526162617511, 0.010757147343576735, 0.013166518923255623, 0.010538712848521859, 0.010574888534728205, 0.010561380429801828, 0.00941893496386538, 0.010738175235391511, 0.010169536786105089, 0.010800003177412464, 0.01118228746725362, 0.01189169197383457, 0.012363599237339758, 0.011686348602531036, 0.010468433611964017, 0.00969719952369112]\n",
      "2018-02-05 13:45:08,305 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:08,498 : INFO : topic #90 (0.009): 0.046*\"whether\" + 0.037*\"treated\" + 0.029*\"run\" + 0.026*\"looking_for\" + 0.010*\"hotel\" + 0.010*\"guests\" + 0.008*\"unique\" + 0.008*\"proved\" + 0.007*\"stay\" + 0.006*\"quickly\"\n",
      "2018-02-05 13:45:08,500 : INFO : topic #41 (0.010): 0.025*\"steaks\" + 0.022*\"kind_of\" + 0.017*\"brief\" + 0.017*\"polite\" + 0.015*\"Marriott\" + 0.013*\"stay_at\" + 0.011*\"room\" + 0.011*\"noted\" + 0.010*\"match\" + 0.007*\"one\"\n",
      "2018-02-05 13:45:08,503 : INFO : topic #10 (0.013): 0.024*\"hotel\" + 0.023*\"room\" + 0.020*\"really\" + 0.013*\"business_trip\" + 0.011*\"friends\" + 0.011*\"day\" + 0.011*\"clean\" + 0.010*\"dining\" + 0.010*\"guests\" + 0.010*\"one\"\n",
      "2018-02-05 13:45:08,505 : INFO : topic #86 (0.013): 0.035*\"hotel\" + 0.013*\"s\" + 0.013*\"room\" + 0.012*\"package\" + 0.011*\"one\" + 0.010*\"great\" + 0.009*\"service\" + 0.009*\"Chicago\" + 0.008*\"food\" + 0.008*\"center\"\n",
      "2018-02-05 13:45:08,508 : INFO : topic #48 (0.013): 0.021*\"wedding\" + 0.020*\"hotel\" + 0.018*\"room\" + 0.017*\"Chicago\" + 0.014*\"luxury\" + 0.013*\"place\" + 0.012*\"really\" + 0.011*\"stay\" + 0.011*\"everything\" + 0.011*\"work\"\n",
      "2018-02-05 13:45:08,522 : INFO : topic diff=6.907185, rho=0.577350\n",
      "2018-02-05 13:45:11,046 : INFO : -16.687 per-word bound, 105512.5 perplexity estimate based on a held-out corpus of 400 documents with 32101 words\n",
      "2018-02-05 13:45:11,047 : INFO : PROGRESS: pass 0, at document #1600/1600\n",
      "2018-02-05 13:45:12,360 : INFO : optimized alpha [0.012185973502696276, 0.011351873790714452, 0.011535552078160219, 0.011039331667586407, 0.012717255216867925, 0.013573681561831644, 0.011098970794598689, 0.012369269133220648, 0.012641766621263038, 0.01167201904076289, 0.01498444487978591, 0.012232416220791527, 0.01253727114936566, 0.013947942266405942, 0.011164338721842453, 0.01094083665716748, 0.011703793784169688, 0.010434834253919384, 0.011069639519614427, 0.013619730741834231, 0.01325660329789913, 0.00955596110086473, 0.013782278788192, 0.010722489534732831, 0.011006064489146155, 0.01052721341705531, 0.014280783875916359, 0.011490514823663426, 0.012429892348416302, 0.011706928680034829, 0.01248421015947853, 0.011033435623436621, 0.0116648521153998, 0.010720125023280833, 0.010191237494620222, 0.011334074115621318, 0.014496174151140174, 0.009601294529485313, 0.010249649018621472, 0.013411376515120524, 0.011683955636247155, 0.009521700084841588, 0.011341229745938796, 0.01075142715859333, 0.01100940315683853, 0.010459488942319727, 0.011298113877751651, 0.011792963275186667, 0.014738037621648652, 0.011060029806349245, 0.012609524333444012, 0.011899056762061079, 0.010977785830107232, 0.011633269107087604, 0.013917047520111558, 0.011966813699231745, 0.011462638956867964, 0.010923218076045828, 0.01016437332382875, 0.010353285760281798, 0.012875338703408224, 0.011003595484499085, 0.012588955821297909, 0.011709832723492677, 0.014985283647489215, 0.012648587517842829, 0.01239169673051142, 0.010787146911159656, 0.011439122435595035, 0.01394869060440472, 0.010223780092401727, 0.011765130067800477, 0.012498810031164976, 0.010751778883671258, 0.010252422790258352, 0.010876555765779668, 0.01127853054391063, 0.01179519829817482, 0.01087792933346521, 0.0118629382019661, 0.011063809862468927, 0.01190573186131826, 0.01023253747963021, 0.010453242785790712, 0.017956426676533615, 0.011280376439947854, 0.014759792713142449, 0.01076981113849666, 0.010874945879360515, 0.010820853505262365, 0.009458427006149715, 0.01116161995856621, 0.010620849893654334, 0.011308475279899652, 0.012368382493840441, 0.01294235432771278, 0.013437978891347253, 0.014080296385717665, 0.01075494116617148, 0.010172085375937492]\n",
      "2018-02-05 13:45:12,372 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:12,547 : INFO : topic #90 (0.009): 0.037*\"whether\" + 0.027*\"treated\" + 0.025*\"looking_for\" + 0.019*\"run\" + 0.019*\"my_bags\" + 0.017*\"proved\" + 0.014*\"revisit\" + 0.014*\"InterContinental_Chicago\" + 0.013*\"followed\" + 0.010*\"guests\"\n",
      "2018-02-05 13:45:12,548 : INFO : topic #41 (0.010): 0.078*\"kind_of\" + 0.040*\"match\" + 0.015*\"be_returning\" + 0.011*\"steaks\" + 0.010*\"lack_of\" + 0.008*\"stay_at\" + 0.008*\"rendered\" + 0.008*\"space\" + 0.008*\"brief\" + 0.008*\"polite\"\n",
      "2018-02-05 13:45:12,550 : INFO : topic #64 (0.015): 0.036*\"sheets\" + 0.027*\"carpet\" + 0.016*\"counter\" + 0.015*\"water\" + 0.014*\"non_smoking\" + 0.013*\"new\" + 0.011*\"price\" + 0.011*\"charge\" + 0.010*\"will_never\" + 0.009*\"worst\"\n",
      "2018-02-05 13:45:12,552 : INFO : topic #10 (0.015): 0.031*\"room\" + 0.027*\"hotel\" + 0.020*\"terrible\" + 0.018*\"really\" + 0.015*\"smell\" + 0.012*\"one\" + 0.012*\"us\" + 0.011*\"like\" + 0.010*\"guests\" + 0.010*\"place\"\n",
      "2018-02-05 13:45:12,554 : INFO : topic #84 (0.018): 0.012*\"clerk\" + 0.008*\"odor\" + 0.007*\"smelled_like\" + 0.006*\"hadn_t\" + 0.006*\"awful\" + 0.006*\"refused\" + 0.005*\"establishment\" + 0.005*\"recent_stay\" + 0.005*\"promised\" + 0.004*\"going_back\"\n",
      "2018-02-05 13:45:12,564 : INFO : topic diff=7.296615, rho=0.500000\n",
      "2018-02-05 13:45:12,635 : INFO : PROGRESS: pass 1, at document #400/1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:45:13,220 : INFO : optimized alpha [0.012180908225816493, 0.011327081763108348, 0.011530756073933371, 0.010894368034897356, 0.013031289815925893, 0.013863213031323044, 0.011078352458434956, 0.012450634645286207, 0.012601532606468497, 0.011797124602306345, 0.015333558848613139, 0.012249978361402979, 0.012565108159247806, 0.014013563598595104, 0.01114218834424768, 0.011058318861588172, 0.011537416399948222, 0.010319506495099282, 0.011165355057470983, 0.0137239086976971, 0.0134231824091446, 0.009396248840722926, 0.013726053324830035, 0.01074440936924483, 0.01098771957744048, 0.010410267527072088, 0.01425731459479849, 0.011522525931722108, 0.012602306626189767, 0.011663001187524176, 0.01236812595715727, 0.011209717150522222, 0.011718004441767207, 0.010563469281996479, 0.010103804908499266, 0.011273768953935816, 0.014528839554130526, 0.009459849196825574, 0.010139635577256136, 0.013480378813915412, 0.011700950359203597, 0.009421907698984417, 0.011268298273406118, 0.01064845674814814, 0.010889891179790657, 0.010279022818994876, 0.011472547062309239, 0.011732750674040147, 0.014994012779021867, 0.01101794042863184, 0.012661215755609852, 0.012159153041911227, 0.010994280004427323, 0.011673733421471566, 0.013959741803166094, 0.012065906791109473, 0.01136302237924003, 0.010894193538948585, 0.010098641946039266, 0.010219285660542995, 0.012909038406378096, 0.011089631283204738, 0.012589350137173336, 0.011604851404670165, 0.014700676872719495, 0.012608820564145775, 0.012705121680366777, 0.010751409733807966, 0.011448649730282836, 0.014387065269265809, 0.01011491765148998, 0.011853638833608121, 0.01255058248181052, 0.010682666843041012, 0.010111184359498853, 0.010816555558247464, 0.011417375409680375, 0.011857954143072105, 0.010894731966920531, 0.011679214432283319, 0.011332474146428696, 0.01196650238171535, 0.010175720692053436, 0.010338642895614194, 0.017392699086138733, 0.011326882409359277, 0.01519066362749715, 0.010800395539910355, 0.010984795441185349, 0.010762347955657323, 0.009350413791957515, 0.01127867306192781, 0.010598508736851708, 0.011202734219810979, 0.012308022368666748, 0.013053675732956647, 0.013842786124637046, 0.01392548461665537, 0.010775218531689923, 0.01001211797498754]\n",
      "2018-02-05 13:45:13,233 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:13,413 : INFO : topic #90 (0.009): 0.038*\"whether\" + 0.025*\"proved\" + 0.023*\"treated\" + 0.018*\"looking_for\" + 0.016*\"run\" + 0.014*\"my_bags\" + 0.012*\"exploring\" + 0.010*\"revisit\" + 0.010*\"InterContinental_Chicago\" + 0.010*\"followed\"\n",
      "2018-02-05 13:45:13,415 : INFO : topic #21 (0.009): 0.025*\"imagined\" + 0.024*\"cell_phone\" + 0.018*\"fiance\" + 0.016*\"either\" + 0.015*\"errors\" + 0.013*\"Last\" + 0.012*\"bothering\" + 0.011*\"pretentious\" + 0.008*\"fill\" + 0.008*\"mignon\"\n",
      "2018-02-05 13:45:13,418 : INFO : topic #86 (0.015): 0.033*\"hotel\" + 0.015*\"s\" + 0.014*\"room\" + 0.011*\"finally\" + 0.011*\"great\" + 0.009*\"one\" + 0.009*\"good\" + 0.008*\"service\" + 0.008*\"Chicago\" + 0.008*\"package\"\n",
      "2018-02-05 13:45:13,420 : INFO : topic #10 (0.015): 0.029*\"room\" + 0.025*\"hotel\" + 0.017*\"really\" + 0.013*\"terrible\" + 0.013*\"us\" + 0.011*\"clean\" + 0.011*\"smell\" + 0.010*\"like\" + 0.010*\"one\" + 0.009*\"spent\"\n",
      "2018-02-05 13:45:13,421 : INFO : topic #84 (0.017): 0.012*\"clerk\" + 0.008*\"odor\" + 0.007*\"smelled_like\" + 0.006*\"hadn_t\" + 0.006*\"awful\" + 0.006*\"refused\" + 0.005*\"establishment\" + 0.005*\"recent_stay\" + 0.004*\"promised\" + 0.004*\"going_back\"\n",
      "2018-02-05 13:45:13,431 : INFO : topic diff=4.005720, rho=0.408248\n",
      "2018-02-05 13:45:13,506 : INFO : PROGRESS: pass 1, at document #800/1600\n",
      "2018-02-05 13:45:14,543 : INFO : optimized alpha [0.012854648770316822, 0.011962523863425174, 0.011756193152263228, 0.01117407590535117, 0.013647774932238297, 0.014251075132362252, 0.011382392663574175, 0.01318347034014536, 0.013457052099785408, 0.012181510304233778, 0.016470390794898718, 0.012740493298096801, 0.013251132108051688, 0.015273606749980155, 0.011456694403967864, 0.011247708259119324, 0.01228905583150239, 0.010581343588979835, 0.011355065812108328, 0.01492544117734617, 0.014163737802142602, 0.009342339322088604, 0.014867476550796697, 0.010911632643952817, 0.011359735353688116, 0.010480878380299633, 0.01564563506908676, 0.011936637608686032, 0.01310183990086552, 0.011998174342250171, 0.013225847232723294, 0.011387711587584629, 0.012145056528016137, 0.010894152174329584, 0.010250427272265362, 0.011649565374291987, 0.015877100460941877, 0.009335756332634544, 0.010162341647779669, 0.01486996023941574, 0.012219247653105085, 0.009385988447929898, 0.011875410824575366, 0.011116552557751506, 0.011386673068121857, 0.010491189512564843, 0.011838500586695866, 0.01233497775579429, 0.015956275872008385, 0.01136611702743655, 0.013359142118610686, 0.012762626698805317, 0.011308040346629413, 0.012069178152119872, 0.014586802962820748, 0.012607342140009949, 0.011740935449359741, 0.011096234916522412, 0.010100845409482707, 0.010259390704915003, 0.013931420615638162, 0.011211255164295972, 0.013576356829024687, 0.012376616723198728, 0.016895503773035406, 0.013224509247932281, 0.01311552181144607, 0.010919345413490949, 0.01160266236318886, 0.015551928048615847, 0.01019024731518385, 0.012265103103964435, 0.013493730907255148, 0.011091067781222966, 0.010300667505773716, 0.011184743923855761, 0.011902251965858701, 0.012252923800344852, 0.011083545933042773, 0.012423623160656672, 0.01131035796787862, 0.012460501848400259, 0.010280821191235854, 0.010570363356107249, 0.02172993530130679, 0.011754063276821542, 0.016324482667884936, 0.011145236642327406, 0.011106435949359688, 0.01104049326506492, 0.009220074355717863, 0.011362873653453901, 0.010800385732934454, 0.011542911167343043, 0.01306159323065519, 0.014025542809913931, 0.014674844963270844, 0.015114918637515934, 0.0109768712794724, 0.01010780283188199]\n",
      "2018-02-05 13:45:14,555 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:14,749 : INFO : topic #90 (0.009): 0.033*\"whether\" + 0.026*\"treated\" + 0.025*\"run\" + 0.017*\"proved\" + 0.015*\"looking_for\" + 0.009*\"my_bags\" + 0.008*\"exploring\" + 0.007*\"revisit\" + 0.007*\"InterContinental_Chicago\" + 0.007*\"followed\"\n",
      "2018-02-05 13:45:14,757 : INFO : topic #37 (0.009): 0.040*\"my_family\" + 0.028*\"nicer\" + 0.014*\"ring\" + 0.013*\"foods\" + 0.011*\"avenue\" + 0.011*\"right\" + 0.011*\"WE\" + 0.011*\"OF\" + 0.010*\"HERE\" + 0.010*\"michigan\"\n",
      "2018-02-05 13:45:14,759 : INFO : topic #10 (0.016): 0.030*\"room\" + 0.026*\"hotel\" + 0.017*\"really\" + 0.016*\"terrible\" + 0.014*\"us\" + 0.012*\"guests\" + 0.011*\"one\" + 0.009*\"sent\" + 0.009*\"clean\" + 0.009*\"spent\"\n",
      "2018-02-05 13:45:14,763 : INFO : topic #64 (0.017): 0.022*\"sheets\" + 0.019*\"carpet\" + 0.019*\"charge\" + 0.018*\"water\" + 0.011*\"price\" + 0.010*\"room\" + 0.009*\"new\" + 0.007*\"don_t\" + 0.007*\"non_smoking\" + 0.007*\"pay\"\n",
      "2018-02-05 13:45:14,764 : INFO : topic #84 (0.022): 0.005*\"clerk\" + 0.004*\"broken\" + 0.004*\"wasn_t\" + 0.004*\"awful\" + 0.004*\"account\" + 0.003*\"speak\" + 0.003*\"policy\" + 0.003*\"odor\" + 0.003*\"refused\" + 0.003*\"non_smoking\"\n",
      "2018-02-05 13:45:14,774 : INFO : topic diff=2.945404, rho=0.408248\n",
      "2018-02-05 13:45:14,859 : INFO : PROGRESS: pass 1, at document #1200/1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:45:15,596 : INFO : optimized alpha [0.013230603350969901, 0.012124902944291948, 0.012164935622717, 0.01142916690081868, 0.01448678762302779, 0.015957059642434337, 0.011888990879051705, 0.013575291726206062, 0.013878009954716653, 0.012721724317237188, 0.01836762634187239, 0.01373069666980113, 0.013808705147497605, 0.01610174710548694, 0.011656540480608856, 0.011610901916804434, 0.012397804745822987, 0.010583117493615408, 0.011735516962666828, 0.015391306087064613, 0.014931088934798397, 0.009381843180889318, 0.015484874517986044, 0.01111151027339417, 0.011465657131003929, 0.01090789816606782, 0.016310301511032178, 0.012398056029124523, 0.014070151435803306, 0.012424399205397707, 0.013556142751263307, 0.0117800345525742, 0.012558057785586338, 0.01087971471989967, 0.010278410435853586, 0.012308392092289499, 0.016922740363454113, 0.009520614102598277, 0.01052808521880946, 0.01508850746772431, 0.012727266326080847, 0.009299962241977978, 0.01193936708379252, 0.011189322743469251, 0.011458347074336064, 0.010633710933795056, 0.012295930984558119, 0.01261954569425568, 0.017990443205443605, 0.01169681544128271, 0.013900647759578146, 0.013159520386456952, 0.011625298530132519, 0.012532333693182301, 0.015846870854395692, 0.012806710362979918, 0.01223913114034598, 0.011420285195957927, 0.010235505938427704, 0.010499245952205246, 0.014195811185053914, 0.01168206414559883, 0.013927680879575698, 0.012447596877983347, 0.01770416195444413, 0.013721985643953287, 0.01397242669178986, 0.01110851487531771, 0.01211604961380815, 0.016153584833658113, 0.010282825680268304, 0.012720939270166513, 0.013673310308652417, 0.011118017698250058, 0.010370138889140488, 0.011385125099865126, 0.012214105816308763, 0.012668995220567475, 0.011511429375491232, 0.012711601557596078, 0.012245090089003588, 0.012994424875839381, 0.010383752546479344, 0.010747058572387823, 0.02425313107625727, 0.012075545446239861, 0.01744390682853074, 0.011357815680862216, 0.011456761594969698, 0.01124075087954032, 0.00935710420193493, 0.012262348530502848, 0.010910552696455671, 0.011863349378655979, 0.013368968125233216, 0.014625527406928674, 0.015514495196912444, 0.015605307628803357, 0.011119348012956855, 0.010251544111115405]\n",
      "2018-02-05 13:45:15,608 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:15,817 : INFO : topic #41 (0.009): 0.050*\"kind_of\" + 0.028*\"steaks\" + 0.025*\"match\" + 0.024*\"brief\" + 0.012*\"polite\" + 0.010*\"be_returning\" + 0.010*\"storage\" + 0.009*\"rendered\" + 0.009*\"space\" + 0.009*\"stay_at\"\n",
      "2018-02-05 13:45:15,819 : INFO : topic #90 (0.009): 0.032*\"whether\" + 0.027*\"treated\" + 0.022*\"run\" + 0.021*\"looking_for\" + 0.015*\"Rex\" + 0.013*\"my_bags\" + 0.012*\"satisfaction\" + 0.011*\"dream\" + 0.010*\"guests\" + 0.010*\"InterContinental_Chicago\"\n",
      "2018-02-05 13:45:15,821 : INFO : topic #48 (0.018): 0.021*\"hotel\" + 0.021*\"Chicago\" + 0.020*\"room\" + 0.019*\"wedding\" + 0.015*\"place\" + 0.013*\"stay\" + 0.013*\"luxury\" + 0.013*\"everything\" + 0.012*\"really\" + 0.012*\"s\"\n",
      "2018-02-05 13:45:15,823 : INFO : topic #10 (0.018): 0.029*\"room\" + 0.028*\"hotel\" + 0.021*\"really\" + 0.013*\"one\" + 0.012*\"clean\" + 0.012*\"place\" + 0.012*\"guests\" + 0.011*\"business_trip\" + 0.011*\"day\" + 0.010*\"friends\"\n",
      "2018-02-05 13:45:15,825 : INFO : topic #84 (0.024): 0.004*\"clerk\" + 0.004*\"wireless\" + 0.004*\"be_able\" + 0.004*\"customer\" + 0.003*\"awful\" + 0.003*\"account\" + 0.003*\"speak\" + 0.003*\"wasn_t\" + 0.003*\"broken\" + 0.003*\"policy\"\n",
      "2018-02-05 13:45:15,836 : INFO : topic diff=2.478666, rho=0.408248\n",
      "2018-02-05 13:45:18,108 : INFO : -10.198 per-word bound, 1174.8 perplexity estimate based on a held-out corpus of 400 documents with 32101 words\n",
      "2018-02-05 13:45:18,110 : INFO : PROGRESS: pass 1, at document #1600/1600\n",
      "2018-02-05 13:45:19,208 : INFO : optimized alpha [0.014429620994137736, 0.012486462486112248, 0.012387356568681809, 0.012251491932765217, 0.01548440309370068, 0.017108716334914318, 0.012480170860036794, 0.014516564953562669, 0.015051224348423913, 0.013182021746281409, 0.0204731626002452, 0.014343071693746687, 0.01476729450303498, 0.017898302249979747, 0.012022303861298565, 0.01203456896543108, 0.013382332612443877, 0.01086782825676582, 0.01216571466802019, 0.017409481699529238, 0.01596733725121172, 0.009460959301827747, 0.017694930184511615, 0.011309998460511221, 0.01189993463635501, 0.011185963288467403, 0.018129354322371845, 0.012840548577085258, 0.014964079678777758, 0.01316495026334644, 0.014621090798621058, 0.012139007760024613, 0.012997603343885679, 0.011446419178366557, 0.010549662139591718, 0.012682671422707016, 0.019068668666526293, 0.009548975024517577, 0.010943161285245674, 0.016514358026741675, 0.013453394754886458, 0.009398649870203994, 0.0125424271406053, 0.01167824339379063, 0.011969335441733233, 0.011268671731204691, 0.012517207923176225, 0.013116064570974825, 0.019407450039567266, 0.01213778753664854, 0.015116658288885376, 0.014034408370880857, 0.012100179649226104, 0.01305324634725371, 0.017140685932633754, 0.013413964826321127, 0.012738832720271072, 0.012029776736154768, 0.010475444675159238, 0.01063177772389131, 0.015393207621077638, 0.011990956129311347, 0.015036871754569608, 0.013596329949431668, 0.021573431332448045, 0.014564275533613122, 0.015034297784191597, 0.01146754209663582, 0.012386822138349091, 0.017332028463867572, 0.010545573770183822, 0.013434923640917005, 0.014646731169561136, 0.011565865763181957, 0.01072895281385726, 0.011714008818375612, 0.012523708100612494, 0.013598579347677511, 0.011968686138631487, 0.013221831088042226, 0.01253023732985877, 0.01361491005743713, 0.0104965144586667, 0.010901294270675037, 0.03160195080257341, 0.012639753908333943, 0.019092856489415774, 0.011497068254038435, 0.01167921199070923, 0.011451402895679731, 0.009378761415153338, 0.012649970372035094, 0.011301014780683663, 0.012334118524574502, 0.014549293043931011, 0.015509404838041451, 0.016474942510155074, 0.0182584110737325, 0.011319245782375581, 0.010680623424077232]\n",
      "2018-02-05 13:45:19,220 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:19,409 : INFO : topic #41 (0.009): 0.069*\"kind_of\" + 0.035*\"match\" + 0.019*\"be_returning\" + 0.015*\"consisted\" + 0.012*\"steaks\" + 0.010*\"acting\" + 0.010*\"brief\" + 0.010*\"destroyed\" + 0.010*\"touted\" + 0.010*\"presence\"\n",
      "2018-02-05 13:45:19,411 : INFO : topic #90 (0.009): 0.029*\"whether\" + 0.021*\"treated\" + 0.019*\"my_bags\" + 0.017*\"looking_for\" + 0.016*\"run\" + 0.014*\"InterContinental_Chicago\" + 0.014*\"followed\" + 0.014*\"proved\" + 0.012*\"guests\" + 0.012*\"satisfaction\"\n",
      "2018-02-05 13:45:19,412 : INFO : topic #10 (0.020): 0.034*\"room\" + 0.031*\"hotel\" + 0.020*\"really\" + 0.019*\"terrible\" + 0.014*\"one\" + 0.013*\"place\" + 0.012*\"smell\" + 0.012*\"guests\" + 0.012*\"clean\" + 0.010*\"us\"\n",
      "2018-02-05 13:45:19,414 : INFO : topic #64 (0.022): 0.033*\"sheets\" + 0.024*\"carpet\" + 0.014*\"water\" + 0.013*\"counter\" + 0.012*\"non_smoking\" + 0.012*\"price\" + 0.012*\"new\" + 0.012*\"room\" + 0.011*\"charge\" + 0.010*\"will_never\"\n",
      "2018-02-05 13:45:19,416 : INFO : topic #84 (0.032): 0.010*\"clerk\" + 0.007*\"odor\" + 0.006*\"awful\" + 0.006*\"smelled_like\" + 0.005*\"refused\" + 0.005*\"hadn_t\" + 0.005*\"wasn_t\" + 0.005*\"establishment\" + 0.005*\"non_smoking\" + 0.004*\"recent_stay\"\n",
      "2018-02-05 13:45:19,426 : INFO : topic diff=1.941360, rho=0.408248\n",
      "2018-02-05 13:45:19,502 : INFO : PROGRESS: pass 2, at document #400/1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:45:20,033 : INFO : optimized alpha [0.014389362917820907, 0.012462763603102958, 0.01236594034991592, 0.012090089360214816, 0.01579216340070866, 0.017410945361234293, 0.012431298247929974, 0.014614243783442747, 0.014981685088570286, 0.013294745923439738, 0.020919047679327517, 0.014289262139154156, 0.014806741823438887, 0.01785686633285285, 0.01199472618437857, 0.012133520141109676, 0.013183799517573827, 0.010768380885698998, 0.012242355129488165, 0.017454803225362678, 0.016091343711581316, 0.009322892644276765, 0.017509868891550366, 0.011330629853673158, 0.011886868736008312, 0.011079218602461647, 0.01803657982298182, 0.01284690391711491, 0.015129891690091232, 0.013114650525974124, 0.014447897327325834, 0.012343892573582765, 0.013038430590719605, 0.011288219135902087, 0.01048821477806659, 0.012605153566598835, 0.01903845089966137, 0.009426557093688824, 0.010831524155187231, 0.016551396504732096, 0.013448091759465534, 0.00931604514099028, 0.012467745743735053, 0.011567993949402914, 0.011830335789157936, 0.011083695311907234, 0.012721264761716807, 0.013014793736234615, 0.019649894195023446, 0.01208571010366148, 0.015147103580226, 0.014328379446401246, 0.012129908446004731, 0.013104345539120566, 0.017176311280695262, 0.013500285039766106, 0.012598769286277605, 0.01200124212008511, 0.010425947793240494, 0.010508240545975985, 0.015373449725216145, 0.0120816656807475, 0.015055494481246054, 0.01345704269398565, 0.020980513956372827, 0.014494322374448039, 0.015416360601759879, 0.011440804302166568, 0.012389795978898369, 0.01780695859122892, 0.010444618205159161, 0.013494849493104429, 0.014684219978895656, 0.011503042767035494, 0.010602884665230477, 0.011648926555073706, 0.012654707647437974, 0.013680234288347515, 0.011953769041447555, 0.013016871466313138, 0.012953453164441717, 0.013670085001334603, 0.010446591985885677, 0.010802269473821543, 0.030063696974756575, 0.012672972418481643, 0.0195523735305389, 0.011513191019559945, 0.011784234361152082, 0.01139258595648731, 0.00929636232634838, 0.012792071697792003, 0.011276748729183146, 0.012230449571107293, 0.014463512798935423, 0.015604197432423115, 0.016929393896373015, 0.01801199048925786, 0.011349464778715228, 0.01052515833215218]\n",
      "2018-02-05 13:45:20,049 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:20,248 : INFO : topic #21 (0.009): 0.022*\"imagined\" + 0.021*\"fiance\" + 0.018*\"either\" + 0.017*\"cell_phone\" + 0.015*\"bothering\" + 0.014*\"Last\" + 0.014*\"errors\" + 0.010*\"papers\" + 0.010*\"mignon\" + 0.010*\"pretentious\"\n",
      "2018-02-05 13:45:20,249 : INFO : topic #41 (0.009): 0.058*\"kind_of\" + 0.030*\"match\" + 0.015*\"brief\" + 0.013*\"be_returning\" + 0.013*\"storage\" + 0.013*\"steaks\" + 0.011*\"space\" + 0.011*\"consisted\" + 0.007*\"nook\" + 0.007*\"NBC\"\n",
      "2018-02-05 13:45:20,251 : INFO : topic #10 (0.021): 0.032*\"room\" + 0.028*\"hotel\" + 0.018*\"really\" + 0.013*\"terrible\" + 0.012*\"clean\" + 0.012*\"us\" + 0.012*\"one\" + 0.011*\"place\" + 0.010*\"staff\" + 0.010*\"like\"\n",
      "2018-02-05 13:45:20,254 : INFO : topic #64 (0.021): 0.032*\"sheets\" + 0.023*\"carpet\" + 0.016*\"water\" + 0.012*\"counter\" + 0.012*\"price\" + 0.012*\"new\" + 0.011*\"non_smoking\" + 0.011*\"room\" + 0.011*\"charge\" + 0.009*\"will_never\"\n",
      "2018-02-05 13:45:20,257 : INFO : topic #84 (0.030): 0.010*\"clerk\" + 0.007*\"odor\" + 0.006*\"awful\" + 0.006*\"smelled_like\" + 0.005*\"refused\" + 0.005*\"hadn_t\" + 0.005*\"wasn_t\" + 0.005*\"establishment\" + 0.004*\"non_smoking\" + 0.004*\"recent_stay\"\n",
      "2018-02-05 13:45:20,269 : INFO : topic diff=1.423111, rho=0.377964\n",
      "2018-02-05 13:45:20,354 : INFO : PROGRESS: pass 2, at document #800/1600\n",
      "2018-02-05 13:45:21,328 : INFO : optimized alpha [0.015204708410223037, 0.013122641631923804, 0.012607353682461386, 0.012365464580854876, 0.016465493175119097, 0.017684601572031226, 0.012743956619642276, 0.015420489334481938, 0.015929241175091896, 0.013713878268549529, 0.022276377179222217, 0.014814680153073318, 0.015521932772719578, 0.01944140739608371, 0.012313175289462682, 0.012327213286852552, 0.013919801130997084, 0.011022098701128757, 0.01243639549927359, 0.0189020025407158, 0.016804980631043746, 0.009290137434177795, 0.018986921470849034, 0.01149228706355633, 0.012286729598699177, 0.011166898766651863, 0.019751716203772064, 0.01325879694093231, 0.01559811969244053, 0.01345811187770841, 0.015400346305740071, 0.012502200829193668, 0.01350042920265191, 0.011633146001690353, 0.010660566720244524, 0.012955173210309902, 0.020840427883433925, 0.009319527426810087, 0.010871187493010614, 0.018164044451517196, 0.01397707028769724, 0.009282679064049951, 0.013041493248182172, 0.012065689556599292, 0.01239092180595656, 0.011290737208438765, 0.013070855946888, 0.013643558601315473, 0.020633181614289762, 0.012441115116318678, 0.01590699214859122, 0.014994283745296785, 0.012438595184784273, 0.013511028952402056, 0.017810467602315905, 0.014108502575694291, 0.01294953852072983, 0.012253246626025949, 0.010440662226533552, 0.010510073949489213, 0.0165068029637044, 0.012252433607004651, 0.01619597453792785, 0.014390961464087653, 0.023573349620762313, 0.015121030215999441, 0.01581450208241649, 0.011624907982141879, 0.012559930760885876, 0.019005192236386862, 0.010558567136353078, 0.013933099981803542, 0.01568775900077453, 0.011936973026402316, 0.010797179873087155, 0.011987941925410946, 0.013127018444447627, 0.014049165854883399, 0.012135530939971433, 0.013757769031667777, 0.012920734013047774, 0.014195001172984284, 0.010530248548840234, 0.01103729771554227, 0.03636917580420964, 0.013137510491503605, 0.020672514501651286, 0.011817040638582488, 0.011899557716131045, 0.011673414193317274, 0.009183930122970942, 0.012873310159359372, 0.011483770512319495, 0.012564966618837051, 0.01533541497210391, 0.016607034276510748, 0.01773211876274232, 0.019296760412359688, 0.011599018219559533, 0.010617981844488197]\n",
      "2018-02-05 13:45:21,341 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:21,536 : INFO : topic #90 (0.009): 0.028*\"whether\" + 0.021*\"treated\" + 0.020*\"run\" + 0.015*\"proved\" + 0.012*\"exploring\" + 0.011*\"my_bags\" + 0.011*\"looking_for\" + 0.008*\"InterContinental_Chicago\" + 0.008*\"followed\" + 0.008*\"guests\"\n",
      "2018-02-05 13:45:21,537 : INFO : topic #21 (0.009): 0.028*\"fiance\" + 0.024*\"either\" + 0.020*\"Monoco\" + 0.019*\"soda\" + 0.018*\"mignon\" + 0.016*\"bothering\" + 0.015*\"Last\" + 0.015*\"imagined\" + 0.014*\"filet\" + 0.014*\"papers\"\n",
      "2018-02-05 13:45:21,540 : INFO : topic #10 (0.022): 0.032*\"room\" + 0.029*\"hotel\" + 0.018*\"really\" + 0.015*\"terrible\" + 0.013*\"guests\" + 0.013*\"us\" + 0.012*\"one\" + 0.011*\"clean\" + 0.010*\"place\" + 0.010*\"this_hotel\"\n",
      "2018-02-05 13:45:21,543 : INFO : topic #64 (0.024): 0.022*\"sheets\" + 0.019*\"carpet\" + 0.018*\"charge\" + 0.017*\"water\" + 0.013*\"room\" + 0.012*\"price\" + 0.009*\"new\" + 0.008*\"bed\" + 0.007*\"just\" + 0.007*\"non_smoking\"\n",
      "2018-02-05 13:45:21,546 : INFO : topic #84 (0.036): 0.005*\"wasn_t\" + 0.004*\"clerk\" + 0.004*\"awful\" + 0.004*\"broken\" + 0.004*\"account\" + 0.003*\"speak\" + 0.003*\"odor\" + 0.003*\"security\" + 0.003*\"non_smoking\" + 0.003*\"room\"\n",
      "2018-02-05 13:45:21,558 : INFO : topic diff=1.018208, rho=0.377964\n",
      "2018-02-05 13:45:21,640 : INFO : PROGRESS: pass 2, at document #1200/1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:45:22,364 : INFO : optimized alpha [0.015583004103332857, 0.013302139715730759, 0.012984835215339007, 0.012615572865194782, 0.01746946838185449, 0.01969734933776764, 0.013267047584487926, 0.015797444504034183, 0.016321292469890288, 0.014299144279312153, 0.02469395260263599, 0.015852675287669114, 0.016110724937575337, 0.020329558121646888, 0.01247177684797985, 0.012698811001156938, 0.014014296329891906, 0.011004371089724775, 0.01281400849863048, 0.019422329674287434, 0.01758796336701695, 0.009324802421775904, 0.019668495201561255, 0.011686614692244572, 0.012386907064345351, 0.011596042193088487, 0.020403495660640134, 0.013796953796355687, 0.016647019400402103, 0.013898121863892282, 0.01573941371664092, 0.012891782182627471, 0.013873033077627004, 0.011626867387843574, 0.010689257706151112, 0.01358367405961431, 0.02204485320467628, 0.009488350714459347, 0.011230564559233274, 0.018331623825244163, 0.014481496261983052, 0.009211684117372047, 0.013120692063421124, 0.012132366655857199, 0.012467594402159114, 0.011417866885467615, 0.013489571358962768, 0.013934656231808909, 0.02305002543940304, 0.012744212539720206, 0.01644869277196296, 0.015321937489753528, 0.012752139700932981, 0.013898876760114684, 0.01928414727722801, 0.01431177343873195, 0.013451062401613673, 0.012550988404870135, 0.010582078136337355, 0.010721799952212832, 0.01680285848965288, 0.012768578855234514, 0.016604674593721447, 0.01446765193970015, 0.0243369245152652, 0.015593001385813609, 0.016762816326436336, 0.011853170721008669, 0.01309194631147266, 0.019506260652120223, 0.01064937742986817, 0.014433733498522727, 0.015847837046302656, 0.011958898354032698, 0.010875292063999203, 0.012171241303168224, 0.013371543272302168, 0.014535698153870565, 0.01258350319669801, 0.014065715751160028, 0.01413144534981286, 0.01481886349832182, 0.010601780002767442, 0.011251299818475984, 0.039625525590868946, 0.013493136321137147, 0.021917774695877454, 0.011989889309815706, 0.012277425123175824, 0.011856983601846128, 0.009325729678897384, 0.013814762188947182, 0.011568287878169489, 0.012916533782986085, 0.015680126099165283, 0.017175470614470983, 0.018568102651689494, 0.019731353834031153, 0.011748304426258896, 0.010737845510504553]\n",
      "2018-02-05 13:45:22,377 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:22,574 : INFO : topic #41 (0.009): 0.048*\"kind_of\" + 0.025*\"steaks\" + 0.024*\"match\" + 0.020*\"brief\" + 0.012*\"be_returning\" + 0.010*\"storage\" + 0.010*\"polite\" + 0.009*\"space\" + 0.009*\"rendered\" + 0.008*\"lack_of\"\n",
      "2018-02-05 13:45:22,576 : INFO : topic #21 (0.009): 0.039*\"fiance\" + 0.023*\"Last\" + 0.022*\"museum\" + 0.017*\"soda\" + 0.016*\"mignon\" + 0.016*\"chicken\" + 0.016*\"either\" + 0.015*\"respectful\" + 0.013*\"Monoco\" + 0.012*\"prepare\"\n",
      "2018-02-05 13:45:22,578 : INFO : topic #64 (0.024): 0.023*\"sheets\" + 0.018*\"carpet\" + 0.016*\"charge\" + 0.016*\"water\" + 0.013*\"room\" + 0.011*\"price\" + 0.008*\"new\" + 0.008*\"bed\" + 0.007*\"don_t\" + 0.007*\"just\"\n",
      "2018-02-05 13:45:22,580 : INFO : topic #10 (0.025): 0.032*\"room\" + 0.030*\"hotel\" + 0.022*\"really\" + 0.014*\"one\" + 0.013*\"clean\" + 0.013*\"place\" + 0.013*\"this_hotel\" + 0.012*\"guests\" + 0.011*\"staff\" + 0.011*\"loved\"\n",
      "2018-02-05 13:45:22,582 : INFO : topic #84 (0.040): 0.005*\"wasn_t\" + 0.004*\"clerk\" + 0.004*\"wireless\" + 0.004*\"customer\" + 0.004*\"awful\" + 0.004*\"be_able\" + 0.004*\"speak\" + 0.004*\"account\" + 0.003*\"broken\" + 0.003*\"handle\"\n",
      "2018-02-05 13:45:22,593 : INFO : topic diff=0.789549, rho=0.377964\n",
      "2018-02-05 13:45:24,857 : INFO : -9.226 per-word bound, 598.7 perplexity estimate based on a held-out corpus of 400 documents with 32101 words\n",
      "2018-02-05 13:45:24,859 : INFO : PROGRESS: pass 2, at document #1600/1600\n",
      "2018-02-05 13:45:25,920 : INFO : optimized alpha [0.016903150585794315, 0.013695800485961978, 0.013224104911976191, 0.01336051422449221, 0.018528409274276056, 0.020934829301224072, 0.013849408299013809, 0.016838503587970254, 0.017686672794265158, 0.014771351155061535, 0.027079649018112793, 0.016502701146975912, 0.017080672689535885, 0.02236000332959291, 0.012816914070829195, 0.013117911171985634, 0.015051463485529812, 0.011269471030638792, 0.013227062218360387, 0.021818395003873055, 0.018637476388367206, 0.009404771769508425, 0.02234573072029728, 0.011878715222297848, 0.012838003237734291, 0.011866899788200637, 0.022593265929978647, 0.014237021479060422, 0.017550517051506308, 0.014608818775164074, 0.016835068588418264, 0.013220388222951367, 0.014320892404003121, 0.012239064156529186, 0.010941769598899207, 0.013913101225926079, 0.02468012631494131, 0.009530490421076227, 0.011626387253497305, 0.020034976445771756, 0.015223284955886046, 0.009309637556982447, 0.013722371721175092, 0.01261659299204404, 0.013033949664281284, 0.012044333409602117, 0.013689304124925963, 0.014427304866610152, 0.024559358885267824, 0.013167694371529788, 0.01773904513251378, 0.016290017885992058, 0.013223500940047442, 0.01432462541411578, 0.020598906466713578, 0.014906926898807678, 0.013946544124523202, 0.013195695040104233, 0.010804178399366593, 0.01081101678498666, 0.01812136419330888, 0.013046604964670493, 0.017883445135407034, 0.015845360173922775, 0.029048397280066782, 0.01640691055675228, 0.017942547654375907, 0.012226493721323915, 0.013392104278448655, 0.02073533414355141, 0.01089318429467531, 0.015161634414100669, 0.01689002195429984, 0.01244419410845914, 0.011233946632695942, 0.01248049700667925, 0.01364823084159523, 0.015539293786165366, 0.013048426892830275, 0.014559679194729901, 0.014355634476087726, 0.015433697908726542, 0.010712647998522135, 0.011422390223580636, 0.050149501278106856, 0.014087204246144975, 0.023625647556199426, 0.012112772855593635, 0.012504370782641954, 0.01204948519578544, 0.009352475519347758, 0.014212952583436606, 0.011949075577489742, 0.013406576652118921, 0.016972586082608633, 0.01810863449367212, 0.019555791007228946, 0.022626886248141267, 0.01195306331534326, 0.011143923701873497]\n",
      "2018-02-05 13:45:25,933 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:26,126 : INFO : topic #41 (0.009): 0.060*\"kind_of\" + 0.034*\"match\" + 0.022*\"be_returning\" + 0.016*\"consisted\" + 0.012*\"steaks\" + 0.011*\"acting\" + 0.010*\"destroyed\" + 0.010*\"touted\" + 0.010*\"presence\" + 0.010*\"Hoping\"\n",
      "2018-02-05 13:45:26,128 : INFO : topic #90 (0.009): 0.027*\"whether\" + 0.020*\"treated\" + 0.016*\"exploring\" + 0.015*\"looking_for\" + 0.015*\"run\" + 0.014*\"InterContinental_Chicago\" + 0.013*\"my_bags\" + 0.013*\"followed\" + 0.013*\"proved\" + 0.012*\"guests\"\n",
      "2018-02-05 13:45:26,129 : INFO : topic #10 (0.027): 0.036*\"room\" + 0.034*\"hotel\" + 0.021*\"really\" + 0.018*\"terrible\" + 0.015*\"one\" + 0.014*\"place\" + 0.014*\"clean\" + 0.012*\"guests\" + 0.012*\"this_hotel\" + 0.010*\"staff\"\n",
      "2018-02-05 13:45:26,131 : INFO : topic #64 (0.029): 0.032*\"sheets\" + 0.023*\"carpet\" + 0.015*\"room\" + 0.014*\"water\" + 0.013*\"price\" + 0.012*\"counter\" + 0.012*\"charge\" + 0.012*\"non_smoking\" + 0.011*\"new\" + 0.009*\"will_never\"\n",
      "2018-02-05 13:45:26,134 : INFO : topic #84 (0.050): 0.009*\"clerk\" + 0.007*\"wasn_t\" + 0.007*\"odor\" + 0.006*\"awful\" + 0.006*\"smelled_like\" + 0.005*\"refused\" + 0.005*\"non_smoking\" + 0.005*\"hadn_t\" + 0.005*\"properly\" + 0.005*\"establishment\"\n",
      "2018-02-05 13:45:26,145 : INFO : topic diff=0.602202, rho=0.377964\n",
      "2018-02-05 13:45:26,223 : INFO : PROGRESS: pass 3, at document #400/1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:45:26,756 : INFO : optimized alpha [0.016818497829989912, 0.013659897449616513, 0.01323355341722947, 0.01316216616072646, 0.018834025817722498, 0.02127680097992665, 0.013759004007796734, 0.0169388222390593, 0.017548634161115344, 0.014831074855192168, 0.027517775515688438, 0.016411389360789685, 0.017164709233909226, 0.02222459921696668, 0.012796266120253802, 0.013221256505416498, 0.01482082953141414, 0.011184474519798298, 0.013272847506052347, 0.021769064247734025, 0.018759335189167402, 0.009282721974431873, 0.022032728356698356, 0.011887799463958761, 0.012818044971156423, 0.011758241736047725, 0.022398222636885238, 0.014228361186905354, 0.017705202956105396, 0.014527215624030865, 0.016613540901808593, 0.013431630195933162, 0.014387644399535982, 0.012076323817733992, 0.010883735080348936, 0.01382133704246196, 0.024537227484357414, 0.009422178731880353, 0.011532988452627803, 0.02002458182118346, 0.015208113005543228, 0.009231506767472485, 0.013610452133925883, 0.012487023693993286, 0.012906381347048015, 0.011855073426719764, 0.013912485689023708, 0.014309291863831751, 0.024781829832836822, 0.013118139853782365, 0.017743907393656406, 0.016562037950161236, 0.01324393629174314, 0.014351615148078025, 0.020624179220229303, 0.015006012081453338, 0.013791245685262127, 0.013155317754085486, 0.010749114506298877, 0.010698081287398704, 0.018051847496363023, 0.013142247520240789, 0.017853770897571213, 0.015644639931430414, 0.02804287980752372, 0.01630784634721223, 0.01835249829746699, 0.012196023224629107, 0.013375505027139334, 0.021218804656219205, 0.010807139876386356, 0.015189304490383472, 0.016895155280152452, 0.012375025837911379, 0.011120159917619962, 0.012400808663772613, 0.013771635078884919, 0.01558575568935034, 0.013023775839026967, 0.014334091132162503, 0.014968535439097284, 0.015467753886023764, 0.010659385603737415, 0.01133515547410828, 0.046691971301201285, 0.0141178651964219, 0.024052389428045128, 0.01211662297012424, 0.012604987257496819, 0.011990396710667308, 0.009281537766296115, 0.01435700562313426, 0.011912364653278778, 0.013291770384188788, 0.01686956663383044, 0.0181668961584736, 0.019986784366547185, 0.02221040849839224, 0.011981171949085156, 0.011002371093658652]\n",
      "2018-02-05 13:45:26,769 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:26,956 : INFO : topic #41 (0.009): 0.053*\"kind_of\" + 0.029*\"match\" + 0.016*\"be_returning\" + 0.013*\"steaks\" + 0.013*\"storage\" + 0.011*\"consisted\" + 0.011*\"space\" + 0.008*\"brief\" + 0.008*\"acting\" + 0.008*\"destroyed\"\n",
      "2018-02-05 13:45:26,958 : INFO : topic #21 (0.009): 0.021*\"fiance\" + 0.021*\"imagined\" + 0.018*\"either\" + 0.014*\"bothering\" + 0.014*\"Last\" + 0.013*\"errors\" + 0.010*\"mignon\" + 0.010*\"papers\" + 0.010*\"primarily\" + 0.010*\"museum\"\n",
      "2018-02-05 13:45:26,960 : INFO : topic #10 (0.028): 0.034*\"room\" + 0.030*\"hotel\" + 0.018*\"really\" + 0.014*\"clean\" + 0.013*\"one\" + 0.012*\"terrible\" + 0.012*\"this_hotel\" + 0.012*\"place\" + 0.011*\"us\" + 0.011*\"staff\"\n",
      "2018-02-05 13:45:26,962 : INFO : topic #64 (0.028): 0.032*\"sheets\" + 0.023*\"carpet\" + 0.015*\"water\" + 0.014*\"room\" + 0.013*\"price\" + 0.012*\"charge\" + 0.011*\"counter\" + 0.011*\"new\" + 0.011*\"non_smoking\" + 0.009*\"will_never\"\n",
      "2018-02-05 13:45:26,964 : INFO : topic #84 (0.047): 0.008*\"clerk\" + 0.007*\"wasn_t\" + 0.007*\"odor\" + 0.006*\"awful\" + 0.006*\"smelled_like\" + 0.005*\"refused\" + 0.005*\"non_smoking\" + 0.005*\"hadn_t\" + 0.005*\"properly\" + 0.004*\"establishment\"\n",
      "2018-02-05 13:45:26,974 : INFO : topic diff=0.459355, rho=0.353553\n",
      "2018-02-05 13:45:27,053 : INFO : PROGRESS: pass 3, at document #800/1600\n",
      "2018-02-05 13:45:28,011 : INFO : optimized alpha [0.017657887351867917, 0.014336723979551476, 0.013493042575362617, 0.013421638283491157, 0.019494503294648677, 0.02142348135938129, 0.01409272241489437, 0.017792787476860403, 0.01860731365443715, 0.015248783661482255, 0.028972366018453294, 0.01697235333893778, 0.017933963120942586, 0.02403887119197834, 0.013074784840581213, 0.0133850924329169, 0.01558786408795998, 0.011422230573061964, 0.013472867933568592, 0.023491323654550807, 0.01949032817754624, 0.009266541254912648, 0.023877343771011677, 0.012045625866909902, 0.013225643924972375, 0.011852786908521649, 0.024487657259197583, 0.014651864900093995, 0.018156692896653056, 0.014879810718657339, 0.017606097985985926, 0.01358283147845341, 0.014836736916525848, 0.012438346884023519, 0.01107172518686766, 0.014192559667468385, 0.026738776383911936, 0.009319579460505923, 0.011558876757357018, 0.02193821615948325, 0.01577260459553261, 0.009207175889647217, 0.014197788525155564, 0.012972573433824826, 0.013481062491943533, 0.01204752122629361, 0.01419632109416197, 0.01495532293160175, 0.025919888903985458, 0.013458359639228036, 0.01850018170321124, 0.01730664285715608, 0.013595387290305265, 0.014793987593370991, 0.021301531956122187, 0.01560720628095189, 0.014114190819268372, 0.013402750598119921, 0.010756075984289624, 0.01069464739579022, 0.019286537942606454, 0.013294874148169284, 0.019153092908432708, 0.01671516513970893, 0.031090634373288926, 0.016970890202836632, 0.018774885549834773, 0.012375231815421491, 0.013551221901741762, 0.022504289235330634, 0.01089990282033949, 0.015642336831602117, 0.018002876955459792, 0.012849044978619347, 0.011300390514358773, 0.012712217705937159, 0.014205007150794664, 0.01597829381720959, 0.013210546029070392, 0.015058351561689607, 0.01491652731323157, 0.01599859424145371, 0.010733681094349846, 0.011575153097059164, 0.05517202860269443, 0.014623727564606122, 0.02516754296362492, 0.012435873416313073, 0.012726467432412911, 0.01227602844515257, 0.009182311768809574, 0.014435353145310942, 0.012146799594168683, 0.013646123356577463, 0.01784445600666779, 0.01916704549230658, 0.0207975338751142, 0.023578167128203507, 0.012225572479605575, 0.011093162385833681]\n",
      "2018-02-05 13:45:28,023 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:28,217 : INFO : topic #41 (0.009): 0.048*\"kind_of\" + 0.034*\"match\" + 0.019*\"steaks\" + 0.015*\"brief\" + 0.013*\"storage\" + 0.012*\"space\" + 0.011*\"lack_of\" + 0.011*\"be_returning\" + 0.010*\"NBC\" + 0.010*\"nook\"\n",
      "2018-02-05 13:45:28,220 : INFO : topic #90 (0.009): 0.027*\"whether\" + 0.020*\"treated\" + 0.019*\"run\" + 0.017*\"exploring\" + 0.014*\"proved\" + 0.010*\"looking_for\" + 0.008*\"InterContinental_Chicago\" + 0.008*\"guests\" + 0.008*\"my_bags\" + 0.008*\"followed\"\n",
      "2018-02-05 13:45:28,222 : INFO : topic #10 (0.029): 0.034*\"room\" + 0.031*\"hotel\" + 0.019*\"really\" + 0.014*\"terrible\" + 0.014*\"one\" + 0.013*\"guests\" + 0.012*\"this_hotel\" + 0.012*\"clean\" + 0.012*\"us\" + 0.011*\"place\"\n",
      "2018-02-05 13:45:28,224 : INFO : topic #64 (0.031): 0.023*\"sheets\" + 0.019*\"carpet\" + 0.018*\"charge\" + 0.017*\"water\" + 0.016*\"room\" + 0.012*\"price\" + 0.009*\"new\" + 0.008*\"bed\" + 0.007*\"just\" + 0.007*\"fix_it\"\n",
      "2018-02-05 13:45:28,226 : INFO : topic #84 (0.055): 0.007*\"wasn_t\" + 0.004*\"awful\" + 0.004*\"clerk\" + 0.004*\"broken\" + 0.004*\"account\" + 0.004*\"room\" + 0.003*\"speak\" + 0.003*\"odor\" + 0.003*\"non_smoking\" + 0.003*\"security\"\n",
      "2018-02-05 13:45:28,236 : INFO : topic diff=0.405114, rho=0.353553\n",
      "2018-02-05 13:45:28,320 : INFO : PROGRESS: pass 3, at document #1200/1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:45:29,030 : INFO : optimized alpha [0.018016984660258573, 0.014522221537709568, 0.013901854105925423, 0.013679483152625448, 0.020574322945707657, 0.023666409907369953, 0.014608303980286723, 0.018212507461432912, 0.018976684460533636, 0.015840858707551544, 0.03181178160381683, 0.018040175304375256, 0.018553226946734964, 0.024919431870344795, 0.013217485188142503, 0.013766500459144125, 0.015667255288690073, 0.011386457001459287, 0.013848624372585789, 0.023972907852185674, 0.02034938266156639, 0.009312569863661644, 0.024501640216373032, 0.012225107604843254, 0.013331878273491445, 0.012255797297722203, 0.025157398141449294, 0.015300383944372054, 0.01924692004006326, 0.015294108084603396, 0.017968183896548976, 0.013983008575897031, 0.015233208159148479, 0.012428083668333978, 0.011110797634142355, 0.014838500969995406, 0.028138916269972378, 0.009482805757996532, 0.011914005080535141, 0.022090541469429653, 0.016270521353351945, 0.009139225012524104, 0.014256207784316707, 0.0130342287807043, 0.013550825758818474, 0.01218166943927754, 0.014663935445624412, 0.015228086073670754, 0.0289704459926736, 0.013770109413963918, 0.019081040774331124, 0.017657272253386327, 0.013894186656400687, 0.015152964093678369, 0.022813927284404494, 0.01578718119858827, 0.014628382492887186, 0.013709344887292108, 0.010904348843240494, 0.010900433423026682, 0.019580651038107577, 0.013835635460185536, 0.019589936729298978, 0.016748803247795343, 0.03178592382748235, 0.01745766055443746, 0.019833630258937775, 0.012599457647825604, 0.01408228000576164, 0.023008577466491622, 0.01099945767739913, 0.016135259690422635, 0.01810714321370626, 0.012865323820985961, 0.01137697932835996, 0.012868916242780588, 0.014431990815841424, 0.016471823950431792, 0.013646763202589946, 0.01537509557095032, 0.01636669212176766, 0.016648718409608923, 0.010786820378827063, 0.011795466872355583, 0.05867863837492374, 0.015030942563238536, 0.026512812544155363, 0.012582673156249188, 0.013089110364938884, 0.012455704684032731, 0.009320028837867485, 0.015382850311404185, 0.012207296550061406, 0.014031896587902463, 0.018181378748271027, 0.019739607400061452, 0.021644327728578782, 0.02399875100476136, 0.012382386928658616, 0.011191092836725083]\n",
      "2018-02-05 13:45:29,042 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:29,237 : INFO : topic #41 (0.009): 0.045*\"kind_of\" + 0.024*\"match\" + 0.024*\"steaks\" + 0.013*\"be_returning\" + 0.011*\"brief\" + 0.010*\"storage\" + 0.008*\"rendered\" + 0.008*\"space\" + 0.008*\"lack_of\" + 0.008*\"polite\"\n",
      "2018-02-05 13:45:29,239 : INFO : topic #21 (0.009): 0.037*\"fiance\" + 0.022*\"Last\" + 0.020*\"museum\" + 0.019*\"soda\" + 0.016*\"prepare\" + 0.015*\"either\" + 0.015*\"mignon\" + 0.015*\"chicken\" + 0.014*\"respectful\" + 0.012*\"Monoco\"\n",
      "2018-02-05 13:45:29,241 : INFO : topic #64 (0.032): 0.024*\"sheets\" + 0.018*\"carpet\" + 0.016*\"charge\" + 0.016*\"room\" + 0.016*\"water\" + 0.011*\"price\" + 0.008*\"new\" + 0.008*\"bed\" + 0.007*\"just\" + 0.007*\"don_t\"\n",
      "2018-02-05 13:45:29,242 : INFO : topic #10 (0.032): 0.034*\"room\" + 0.032*\"hotel\" + 0.023*\"really\" + 0.015*\"one\" + 0.015*\"this_hotel\" + 0.015*\"clean\" + 0.014*\"place\" + 0.012*\"guests\" + 0.012*\"loved\" + 0.011*\"staff\"\n",
      "2018-02-05 13:45:29,244 : INFO : topic #84 (0.059): 0.007*\"wasn_t\" + 0.004*\"customer\" + 0.004*\"awful\" + 0.004*\"wireless\" + 0.004*\"clerk\" + 0.004*\"be_able\" + 0.004*\"speak\" + 0.004*\"room\" + 0.004*\"account\" + 0.003*\"broken\"\n",
      "2018-02-05 13:45:29,255 : INFO : topic diff=0.336723, rho=0.353553\n",
      "2018-02-05 13:45:31,534 : INFO : -9.086 per-word bound, 543.5 perplexity estimate based on a held-out corpus of 400 documents with 32101 words\n",
      "2018-02-05 13:45:31,535 : INFO : PROGRESS: pass 3, at document #1600/1600\n",
      "2018-02-05 13:45:32,556 : INFO : optimized alpha [0.01942727093443007, 0.014925394902962526, 0.014196634478735797, 0.014377877708503878, 0.02170073258826708, 0.024860753851952085, 0.015141668309622582, 0.019394728223171977, 0.020435348038300365, 0.016297315445836527, 0.03442179359529083, 0.01868050674805133, 0.019594742809074035, 0.027189129099847845, 0.013520798619480813, 0.01413330809566154, 0.01669115443195713, 0.011634597230010282, 0.014270100800697941, 0.026944480686073295, 0.021473324845503097, 0.00940099399120159, 0.02764077471852758, 0.012423463279984706, 0.013779136616246765, 0.012499550474659166, 0.0278404479169774, 0.015739199115000515, 0.02014478335339633, 0.016024332632550726, 0.019136059410148728, 0.014306683387397951, 0.015705216026996933, 0.013035800343590823, 0.011357267611316273, 0.015122894564547304, 0.03132869669010582, 0.009527806983606247, 0.012293437257460066, 0.024113597405748612, 0.01699843619068047, 0.009228161348259507, 0.014882415332649964, 0.01352687974126589, 0.01413013170031872, 0.012781612563210382, 0.014829370603933932, 0.01573156976756059, 0.03055148360114402, 0.014190129390454446, 0.02047262577341705, 0.018680040395461575, 0.014376799790394702, 0.015534280807313842, 0.02415612774718607, 0.0163839705585075, 0.015108408929304346, 0.014357387319694055, 0.011120629517546094, 0.01097039113548774, 0.020936138367581108, 0.014108295358165377, 0.020934204291657214, 0.018286561899905983, 0.037300100993558155, 0.018299449689909698, 0.021067079728866817, 0.01297806563531883, 0.014389472924868871, 0.02422790059478779, 0.011236817105055693, 0.016875597490259842, 0.019219508848984487, 0.013335986987519933, 0.01171797084530134, 0.013149266986598573, 0.014727796468420519, 0.017494385334004613, 0.014109233671670844, 0.015825386219912488, 0.016502168802271833, 0.01725450199779614, 0.010896471549052537, 0.011962587449793173, 0.07231388095940793, 0.015727082681169017, 0.028332376423827053, 0.012668808745561106, 0.013287288374951734, 0.012654545570110228, 0.009342110336994405, 0.015778555509743965, 0.012603005171882248, 0.01449537948743427, 0.01965737957485279, 0.020752105650290602, 0.022681188315040488, 0.027142963652579195, 0.012604326525232665, 0.011567671589938835]\n",
      "2018-02-05 13:45:32,570 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:32,763 : INFO : topic #41 (0.009): 0.055*\"kind_of\" + 0.033*\"match\" + 0.023*\"be_returning\" + 0.015*\"consisted\" + 0.012*\"steaks\" + 0.010*\"acting\" + 0.010*\"touted\" + 0.010*\"destroyed\" + 0.010*\"presence\" + 0.010*\"Hoping\"\n",
      "2018-02-05 13:45:32,765 : INFO : topic #90 (0.009): 0.027*\"whether\" + 0.022*\"treated\" + 0.018*\"exploring\" + 0.014*\"InterContinental_Chicago\" + 0.014*\"run\" + 0.013*\"followed\" + 0.012*\"proved\" + 0.012*\"guests\" + 0.012*\"looking_for\" + 0.012*\"satisfaction\"\n",
      "2018-02-05 13:45:32,767 : INFO : topic #10 (0.034): 0.037*\"room\" + 0.035*\"hotel\" + 0.021*\"really\" + 0.017*\"terrible\" + 0.016*\"one\" + 0.015*\"clean\" + 0.015*\"place\" + 0.014*\"this_hotel\" + 0.012*\"guests\" + 0.011*\"staff\"\n",
      "2018-02-05 13:45:32,769 : INFO : topic #64 (0.037): 0.032*\"sheets\" + 0.023*\"carpet\" + 0.018*\"room\" + 0.014*\"water\" + 0.013*\"price\" + 0.012*\"charge\" + 0.011*\"counter\" + 0.011*\"non_smoking\" + 0.010*\"new\" + 0.009*\"worst\"\n",
      "2018-02-05 13:45:32,771 : INFO : topic #84 (0.072): 0.008*\"wasn_t\" + 0.008*\"clerk\" + 0.007*\"odor\" + 0.006*\"awful\" + 0.005*\"smelled_like\" + 0.005*\"refused\" + 0.005*\"non_smoking\" + 0.005*\"properly\" + 0.004*\"establishment\" + 0.004*\"television\"\n",
      "2018-02-05 13:45:32,782 : INFO : topic diff=0.344755, rho=0.353553\n",
      "2018-02-05 13:45:32,860 : INFO : PROGRESS: pass 4, at document #400/1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:45:33,404 : INFO : optimized alpha [0.019276660805409903, 0.014889296507708621, 0.014222769265271938, 0.01418023645976772, 0.021959646007208712, 0.025159139800429355, 0.015035152404204888, 0.01946146638444408, 0.02021820454205628, 0.016341545428185354, 0.03468189835892042, 0.018581025451894113, 0.019662313282884883, 0.026907430797206866, 0.013486291259793946, 0.014230395529930644, 0.016429051171562476, 0.011563055927580628, 0.01430841691936882, 0.026731357730142808, 0.02155445029626577, 0.009290585249805776, 0.02715338465409178, 0.01242144330947606, 0.01375209178721932, 0.012389504307661987, 0.027496439083455924, 0.015752408021226422, 0.020235110308691687, 0.01592410328131971, 0.018877535142539332, 0.014513284336682017, 0.015746610442519137, 0.012878530954464925, 0.01130105789623863, 0.015029704150609433, 0.031006085598907784, 0.009430447322560235, 0.01220776788881947, 0.024011395019822315, 0.016959262674618662, 0.009160504172021482, 0.014757100393009207, 0.013389452331087464, 0.013990329025411717, 0.012588462453864458, 0.01509767326441884, 0.015596688951988385, 0.030695229743546014, 0.014155129310993539, 0.020429668120577487, 0.018968856015017493, 0.014387229577286206, 0.015563690092871825, 0.02412893196718657, 0.01647006437496988, 0.014938952893415205, 0.01429331026391153, 0.01106898884378121, 0.01086630008554973, 0.0208098588174249, 0.01420917730571475, 0.02084429046307209, 0.018074571792574236, 0.03575754114804917, 0.018168852783577858, 0.021464758632008852, 0.01296539227479364, 0.01437713879482484, 0.0246693996439626, 0.011154763623441633, 0.016896969038982666, 0.01918727135223948, 0.01327099709056539, 0.011596156590273243, 0.013056614497259656, 0.014819854986637227, 0.017530678251377767, 0.01406312906842335, 0.015594564231206077, 0.017309022177031272, 0.01728018799067008, 0.01084893380103525, 0.011875602186374705, 0.06583055013059395, 0.01573963495501577, 0.028698650846605923, 0.012671764667787268, 0.013384014556909612, 0.012594480099028634, 0.009279968741281112, 0.015911259235103017, 0.012564087193832174, 0.014369109480050508, 0.01949815721003844, 0.020768253322464018, 0.02305525390617335, 0.02653317725225824, 0.012630024827065338, 0.01142974311891427]\n",
      "2018-02-05 13:45:33,416 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:33,609 : INFO : topic #41 (0.009): 0.049*\"kind_of\" + 0.029*\"match\" + 0.017*\"be_returning\" + 0.013*\"steaks\" + 0.012*\"storage\" + 0.011*\"consisted\" + 0.010*\"space\" + 0.009*\"room\" + 0.007*\"touted\" + 0.007*\"acting\"\n",
      "2018-02-05 13:45:33,611 : INFO : topic #90 (0.009): 0.029*\"whether\" + 0.024*\"exploring\" + 0.020*\"treated\" + 0.017*\"proved\" + 0.012*\"run\" + 0.011*\"InterContinental_Chicago\" + 0.010*\"guests\" + 0.010*\"followed\" + 0.010*\"looking_for\" + 0.009*\"satisfaction\"\n",
      "2018-02-05 13:45:33,613 : INFO : topic #10 (0.035): 0.035*\"room\" + 0.032*\"hotel\" + 0.019*\"really\" + 0.015*\"clean\" + 0.014*\"one\" + 0.014*\"this_hotel\" + 0.013*\"place\" + 0.012*\"terrible\" + 0.012*\"staff\" + 0.011*\"us\"\n",
      "2018-02-05 13:45:33,615 : INFO : topic #64 (0.036): 0.032*\"sheets\" + 0.023*\"carpet\" + 0.018*\"room\" + 0.015*\"water\" + 0.013*\"price\" + 0.012*\"charge\" + 0.011*\"counter\" + 0.011*\"new\" + 0.010*\"non_smoking\" + 0.008*\"worst\"\n",
      "2018-02-05 13:45:33,617 : INFO : topic #84 (0.066): 0.008*\"wasn_t\" + 0.008*\"clerk\" + 0.007*\"odor\" + 0.006*\"awful\" + 0.005*\"smelled_like\" + 0.005*\"refused\" + 0.005*\"non_smoking\" + 0.005*\"properly\" + 0.004*\"establishment\" + 0.004*\"room\"\n",
      "2018-02-05 13:45:33,629 : INFO : topic diff=0.299671, rho=0.333333\n",
      "2018-02-05 13:45:33,709 : INFO : PROGRESS: pass 4, at document #800/1600\n",
      "2018-02-05 13:45:34,677 : INFO : optimized alpha [0.02017846718060694, 0.015598452214751283, 0.014477694287598708, 0.014435535853377193, 0.02266218017517045, 0.02516337005084865, 0.015365839985228521, 0.02042869645713875, 0.021356745349797954, 0.016757211401354232, 0.036297003396052914, 0.01914591163222144, 0.020452969352033577, 0.028848850139742883, 0.01374879316187726, 0.014376451380572768, 0.01719806631595593, 0.011796020211232414, 0.014490974951811486, 0.028778173853852587, 0.02231347651068194, 0.009287555632499032, 0.029369080972238566, 0.012575899515420636, 0.014145693982668624, 0.012470733762379817, 0.02992421267993487, 0.016202466592887033, 0.020677412703721247, 0.016245859295081662, 0.019874778036690858, 0.014669878957934535, 0.016207998598046294, 0.013237890187743772, 0.011476295403007614, 0.015385758539627014, 0.03348781875654764, 0.009338266137929393, 0.01223048310937711, 0.026207615760518114, 0.017516573862300638, 0.009120240373646574, 0.015359498561832522, 0.013885768981849884, 0.01455700722508117, 0.01277745257767215, 0.015363937745480437, 0.016207811020064623, 0.03182795114936961, 0.014492409989022917, 0.021238162650953046, 0.019766371631841875, 0.014736575294417803, 0.015979116136230626, 0.02484306024860744, 0.01708984281874819, 0.01524557467746448, 0.014524257595729104, 0.01108671522128711, 0.010857771606838673, 0.022159597811202254, 0.014379186693073052, 0.022205837293882105, 0.019205531685373502, 0.039185738307121354, 0.018854229802354426, 0.021869750051200964, 0.013151445087523375, 0.01455900366642603, 0.026049230906683422, 0.011255512528646093, 0.017321226869929315, 0.020339083228337242, 0.01375500760270375, 0.011792611958368131, 0.013352285533300926, 0.015288032997971589, 0.01790337871594463, 0.014256184453328404, 0.016325424552638895, 0.01724353066295111, 0.01781408852826296, 0.010923860433263688, 0.012101700271955156, 0.07613597545778228, 0.016305824338416364, 0.02983520935567676, 0.012964497733571117, 0.013490018113479146, 0.012896576903969533, 0.00919105130139767, 0.01596019851912137, 0.012816004686699486, 0.014732628090074884, 0.020534447629530342, 0.021730671956335216, 0.023858457563949966, 0.028016385126654223, 0.012891883640410863, 0.011528536426348395]\n",
      "2018-02-05 13:45:34,690 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:34,889 : INFO : topic #41 (0.009): 0.044*\"kind_of\" + 0.034*\"match\" + 0.018*\"steaks\" + 0.013*\"storage\" + 0.012*\"be_returning\" + 0.011*\"lack_of\" + 0.011*\"space\" + 0.010*\"room\" + 0.009*\"NBC\" + 0.009*\"nook\"\n",
      "2018-02-05 13:45:34,891 : INFO : topic #90 (0.009): 0.027*\"whether\" + 0.021*\"treated\" + 0.019*\"exploring\" + 0.017*\"run\" + 0.013*\"proved\" + 0.009*\"looking_for\" + 0.009*\"guests\" + 0.009*\"InterContinental_Chicago\" + 0.008*\"room\" + 0.008*\"followed\"\n",
      "2018-02-05 13:45:34,892 : INFO : topic #10 (0.036): 0.034*\"room\" + 0.032*\"hotel\" + 0.019*\"really\" + 0.014*\"one\" + 0.014*\"this_hotel\" + 0.014*\"terrible\" + 0.014*\"clean\" + 0.012*\"guests\" + 0.012*\"place\" + 0.012*\"us\"\n",
      "2018-02-05 13:45:34,894 : INFO : topic #64 (0.039): 0.023*\"sheets\" + 0.019*\"room\" + 0.019*\"carpet\" + 0.018*\"charge\" + 0.017*\"water\" + 0.012*\"price\" + 0.009*\"new\" + 0.008*\"bed\" + 0.007*\"just\" + 0.007*\"fix_it\"\n",
      "2018-02-05 13:45:34,896 : INFO : topic #84 (0.076): 0.008*\"wasn_t\" + 0.004*\"awful\" + 0.004*\"room\" + 0.004*\"one\" + 0.004*\"clerk\" + 0.004*\"broken\" + 0.004*\"account\" + 0.004*\"odor\" + 0.003*\"speak\" + 0.003*\"non_smoking\"\n",
      "2018-02-05 13:45:34,904 : INFO : topic diff=0.320756, rho=0.333333\n",
      "2018-02-05 13:45:34,987 : INFO : PROGRESS: pass 4, at document #1200/1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:45:35,700 : INFO : optimized alpha [0.020527929196006836, 0.01579056689599803, 0.014896940900132138, 0.014677768863645583, 0.023772899161096032, 0.027696430218322875, 0.01589728198864839, 0.020842561868305524, 0.02172856419842077, 0.01735513314150122, 0.039529012966781116, 0.020252139230566478, 0.021152548628998326, 0.02975375559483774, 0.013888450845630698, 0.014755939418557747, 0.017248014838272728, 0.01174313323880583, 0.014890074776416446, 0.029301860576416865, 0.023155188385106835, 0.009335141361257205, 0.029928846450546342, 0.012741961153034847, 0.014234819121644163, 0.012858718266653779, 0.030556795006521253, 0.01689133310001505, 0.02184852418834378, 0.01668718224496792, 0.02021009269339613, 0.01503259526478672, 0.016630364727375693, 0.013223607259019986, 0.01151544747239362, 0.01603639122642508, 0.035071219812049505, 0.009488867629596467, 0.012582534592723243, 0.02626286271703061, 0.018018362935132877, 0.009061867977337972, 0.015422188979536197, 0.013942441471431788, 0.014644395124064773, 0.012908498437960934, 0.015858260558439072, 0.016488931289904796, 0.035304939268527256, 0.014801968737443803, 0.02178651985742883, 0.020106081246075626, 0.015020724094916343, 0.016321496811213296, 0.02642281235176531, 0.017260031480077966, 0.015760422855797446, 0.014804278303168415, 0.011232511539916624, 0.011049489347124547, 0.022429155490421116, 0.014935226467809348, 0.022649782767623142, 0.01917099630566353, 0.03974822554844637, 0.0193401669896642, 0.023057500135720166, 0.013383663453854276, 0.015078270375380296, 0.026482067523680028, 0.011363420605591144, 0.01784663995828108, 0.02044860682552838, 0.013765890327654169, 0.011867984912413206, 0.01350589039021054, 0.015496598628167838, 0.01844623671642392, 0.014668507397430653, 0.016651635999299867, 0.018963286867486336, 0.018459750975955834, 0.010969154659687341, 0.012349081371456636, 0.07919599226686033, 0.016701459182778093, 0.031209324028130977, 0.013108913270948087, 0.013849197840678985, 0.013073138486609057, 0.009325157358499538, 0.016960902745302237, 0.012863281376239759, 0.015129652183767847, 0.020874231790828056, 0.02226483467077041, 0.02472188089543281, 0.028406023244369014, 0.013067387813897307, 0.011605799212029077]\n",
      "2018-02-05 13:45:35,712 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:35,913 : INFO : topic #41 (0.009): 0.042*\"kind_of\" + 0.025*\"match\" + 0.023*\"steaks\" + 0.014*\"be_returning\" + 0.011*\"room\" + 0.010*\"storage\" + 0.009*\"hotel\" + 0.008*\"rendered\" + 0.008*\"lack_of\" + 0.008*\"space\"\n",
      "2018-02-05 13:45:35,915 : INFO : topic #21 (0.009): 0.035*\"fiance\" + 0.021*\"Last\" + 0.020*\"soda\" + 0.019*\"museum\" + 0.018*\"prepare\" + 0.015*\"either\" + 0.015*\"mignon\" + 0.014*\"chicken\" + 0.013*\"respectful\" + 0.012*\"Monoco\"\n",
      "2018-02-05 13:45:35,917 : INFO : topic #10 (0.040): 0.034*\"room\" + 0.033*\"hotel\" + 0.023*\"really\" + 0.016*\"this_hotel\" + 0.016*\"one\" + 0.016*\"clean\" + 0.015*\"place\" + 0.012*\"loved\" + 0.012*\"staff\" + 0.011*\"guests\"\n",
      "2018-02-05 13:45:35,919 : INFO : topic #64 (0.040): 0.024*\"sheets\" + 0.019*\"room\" + 0.018*\"carpet\" + 0.016*\"charge\" + 0.016*\"water\" + 0.011*\"price\" + 0.008*\"bed\" + 0.008*\"new\" + 0.007*\"just\" + 0.007*\"don_t\"\n",
      "2018-02-05 13:45:35,921 : INFO : topic #84 (0.079): 0.008*\"wasn_t\" + 0.004*\"room\" + 0.004*\"awful\" + 0.004*\"one\" + 0.004*\"customer\" + 0.004*\"wireless\" + 0.004*\"speak\" + 0.004*\"be_able\" + 0.004*\"account\" + 0.003*\"clerk\"\n",
      "2018-02-05 13:45:35,931 : INFO : topic diff=0.264783, rho=0.333333\n",
      "2018-02-05 13:45:38,175 : INFO : -9.019 per-word bound, 518.7 perplexity estimate based on a held-out corpus of 400 documents with 32101 words\n",
      "2018-02-05 13:45:38,177 : INFO : PROGRESS: pass 4, at document #1600/1600\n",
      "2018-02-05 13:45:39,192 : INFO : optimized alpha [0.021989183124622575, 0.0161780735689973, 0.015187051609705612, 0.015352254899398893, 0.02491794698700038, 0.028873071695919506, 0.016458102663050107, 0.022146322815663012, 0.02327594364332532, 0.01779444270677362, 0.04233716752971325, 0.02087618709929069, 0.022230514796005876, 0.03216597057240316, 0.014174947223540638, 0.01510681106805645, 0.01829325424965166, 0.011985926005969679, 0.015296167523503075, 0.03285490517740905, 0.02426985237220994, 0.009422826860543932, 0.033535294209349586, 0.012936380513129772, 0.014678805366744796, 0.013098242040193555, 0.03378068571032052, 0.017358082276619165, 0.022708998995601217, 0.01742390298876785, 0.021396611682165067, 0.015364572437493203, 0.017128702688437674, 0.013807028244683188, 0.0117570410404093, 0.016314639704254175, 0.03870776217200097, 0.009535754834937129, 0.01295765919875477, 0.028474605019379623, 0.018786879109789285, 0.009150001308480302, 0.016088535515104987, 0.014433412904485143, 0.015237778358288897, 0.013504527149749928, 0.01600200552921935, 0.017004182351425628, 0.036956473047000546, 0.015244326511838985, 0.0232395489399446, 0.021164371437197814, 0.015527795054961149, 0.01672561105644422, 0.027790577821781272, 0.017829102236238292, 0.016211653529476986, 0.015454679753874469, 0.011453692900750774, 0.011120394013584823, 0.023844355666201186, 0.01519087853387989, 0.02410148546205128, 0.02083095426472269, 0.04600310452014745, 0.020242895885209545, 0.02434975295022145, 0.013747157678457082, 0.015380953702020597, 0.02773083108249385, 0.011595756614230228, 0.01862754523806877, 0.021598292791733927, 0.014234388776436218, 0.012193102444011545, 0.013781356147609279, 0.015786983462763627, 0.019529062390037398, 0.015128973557044048, 0.017127043276953774, 0.019067933967767476, 0.01908368416377298, 0.011050237618436555, 0.012512849871948726, 0.09535506278482725, 0.01738307097520063, 0.03305645418935321, 0.01319325153722908, 0.014019837338415825, 0.01326800724501192, 0.00935027816164048, 0.01733900444585948, 0.013232747211201205, 0.015579001607802921, 0.02248197694765958, 0.023240795382637243, 0.02573619220786742, 0.031846954325713155, 0.013307445205708807, 0.011964923738423058]\n",
      "2018-02-05 13:45:39,205 : INFO : merging changes from 400 documents into a model of 1600 documents\n",
      "2018-02-05 13:45:39,396 : INFO : topic #41 (0.009): 0.052*\"kind_of\" + 0.032*\"match\" + 0.023*\"be_returning\" + 0.015*\"consisted\" + 0.012*\"steaks\" + 0.010*\"hotel\" + 0.010*\"touted\" + 0.010*\"presence\" + 0.010*\"acting\" + 0.010*\"destroyed\"\n",
      "2018-02-05 13:45:39,398 : INFO : topic #21 (0.009): 0.026*\"fiance\" + 0.023*\"imagined\" + 0.020*\"either\" + 0.018*\"prepare\" + 0.017*\"bothering\" + 0.016*\"Last\" + 0.015*\"errors\" + 0.013*\"soda\" + 0.013*\"mignon\" + 0.012*\"papers\"\n",
      "2018-02-05 13:45:39,400 : INFO : topic #10 (0.042): 0.036*\"room\" + 0.035*\"hotel\" + 0.021*\"really\" + 0.016*\"terrible\" + 0.016*\"one\" + 0.016*\"clean\" + 0.015*\"this_hotel\" + 0.015*\"place\" + 0.012*\"guests\" + 0.011*\"staff\"\n",
      "2018-02-05 13:45:39,403 : INFO : topic #64 (0.046): 0.032*\"sheets\" + 0.023*\"carpet\" + 0.020*\"room\" + 0.014*\"water\" + 0.012*\"charge\" + 0.012*\"price\" + 0.011*\"counter\" + 0.011*\"non_smoking\" + 0.010*\"new\" + 0.009*\"worst\"\n",
      "2018-02-05 13:45:39,406 : INFO : topic #84 (0.095): 0.009*\"wasn_t\" + 0.007*\"odor\" + 0.007*\"clerk\" + 0.006*\"awful\" + 0.005*\"smelled_like\" + 0.005*\"refused\" + 0.005*\"non_smoking\" + 0.005*\"room\" + 0.005*\"properly\" + 0.004*\"establishment\"\n",
      "2018-02-05 13:45:39,417 : INFO : topic diff=0.298658, rho=0.333333\n"
     ]
    }
   ],
   "source": [
    "num_topics = 100\n",
    "chunksize = 400\n",
    "passes = 5\n",
    "\n",
    "model = models.LdaModel(corpus_bow, id2word=dictionary, num_topics=num_topics,alpha = 'auto',eta='auto',random_state=0, chunksize=chunksize, passes=passes)\n",
    "# model = models.LdaModel(tfidf[corpus_bow], id2word=dictionary, num_topics=num_topics)\n",
    "# model.update(corpus_bow[500:len(corpus_bow)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_dists = np.zeros([len(sentence_stream2),num_topics])\n",
    "    \n",
    "for i,item in enumerate(corpus_bow):       \n",
    "    dists = model.get_document_topics(item)        \n",
    "    indices = list(dict(dists).keys())        \n",
    "    vals = list(dict(dists).values())        \n",
    "    topic_dists[i,indices] = vals\n",
    "\n",
    "topic_dists = pd.DataFrame(topic_dists, columns = ['topic'+str(a) for a in range(num_topics)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_tp_dists = np.zeros([len(raw_corpus_bow),num_topics])\n",
    "# for i,item in enumerate(raw_corpus_bow):\n",
    "#     if (i% 1000)== 0:\n",
    "#         print(i)\n",
    "#     dists = model.get_document_topics(item)        \n",
    "#     indices = list(dict(dists).keys())        \n",
    "#     vals = list(dict(dists).values())        \n",
    "#     raw_tp_dists[i,indices] = vals\n",
    "# raw_tp_dists = pd.DataFrame(raw_tp_dists, columns = ['topic'+str(a) for a in range(num_topics)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_dists = list(model[tfidf[corpus_bow]])\n",
    "# topic_dists = [ [c for (b,c) in a  ]for a in topic_dists]\n",
    "# topic_dists = pd.DataFrame(topic_dists,columns = ['topic'+str(a) for a in range(num_topics)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic90</th>\n",
       "      <th>topic91</th>\n",
       "      <th>topic92</th>\n",
       "      <th>topic93</th>\n",
       "      <th>topic94</th>\n",
       "      <th>topic95</th>\n",
       "      <th>topic96</th>\n",
       "      <th>topic97</th>\n",
       "      <th>topic98</th>\n",
       "      <th>topic99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic0  topic1  topic2  topic3    topic4  topic5  topic6    topic7  \\\n",
       "0  0.000000     0.0     0.0     0.0  0.000000     0.0     0.0  0.000000   \n",
       "1  0.000000     0.0     0.0     0.0  0.000000     0.0     0.0  0.000000   \n",
       "2  0.042672     0.0     0.0     0.0  0.020658     0.0     0.0  0.059842   \n",
       "3  0.000000     0.0     0.0     0.0  0.000000     0.0     0.0  0.000000   \n",
       "\n",
       "   topic8  topic9   ...     topic90  topic91  topic92  topic93  topic94  \\\n",
       "0     0.0     0.0   ...         0.0      0.0      0.0      0.0      0.0   \n",
       "1     0.0     0.0   ...         0.0      0.0      0.0      0.0      0.0   \n",
       "2     0.0     0.0   ...         0.0      0.0      0.0      0.0      0.0   \n",
       "3     0.0     0.0   ...         0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   topic95  topic96  topic97  topic98  topic99  \n",
       "0      0.0      0.0      0.0      0.0      0.0  \n",
       "1      0.0      0.0      0.0      0.0      0.0  \n",
       "2      0.0      0.0      0.0      0.0      0.0  \n",
       "3      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[4 rows x 100 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dists.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:45:42,985 : INFO : collecting all words and their counts\n",
      "2018-02-05 13:45:42,989 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-02-05 13:45:43,018 : INFO : collected 11389 word types and 1600 unique tags from a corpus of 1600 examples and 111597 words\n",
      "2018-02-05 13:45:43,020 : INFO : Loading a fresh vocabulary\n",
      "2018-02-05 13:45:43,039 : INFO : min_count=1 retains 11389 unique words (100% of original 11389, drops 0)\n",
      "2018-02-05 13:45:43,040 : INFO : min_count=1 leaves 111597 word corpus (100% of original 111597, drops 0)\n",
      "2018-02-05 13:45:43,094 : INFO : deleting the raw counts dictionary of 11389 items\n",
      "2018-02-05 13:45:43,095 : INFO : sample=0.001 downsamples 33 most-common words\n",
      "2018-02-05 13:45:43,097 : INFO : downsampling leaves estimated 104666 word corpus (93.8% of prior 111597)\n",
      "2018-02-05 13:45:43,098 : INFO : estimated required memory for 11389 words and 100 dimensions: 15445700 bytes\n",
      "2018-02-05 13:45:43,125 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "turk_model = gensim.models.doc2vec.Doc2Vec(dm=0, size=100,min_count=1, window=5,workers=cores, seed=8, negative=5)\n",
    "turk_model.build_vocab(true_fake_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-05 13:45:43,283 : INFO : training model with 8 workers on 11389 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-02-05 13:45:43,905 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-02-05 13:45:43,913 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-02-05 13:45:43,924 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-02-05 13:45:43,938 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-02-05 13:45:43,943 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-02-05 13:45:43,947 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-02-05 13:45:43,948 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-02-05 13:45:43,950 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-02-05 13:45:43,951 : INFO : training on 557985 raw words (531317 effective words) took 0.7s, 808427 effective words/s\n",
      "2018-02-05 13:45:43,952 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "531317"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turk_model.train(true_fake_corpus, total_examples=turk_model.corpus_count, epochs=turk_model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "true_fake_vec = pd.DataFrame([turk_model.infer_vector(s.words) for s in true_fake_corpus])\n",
    "\n",
    "# vader_sent = vader_sent.apply(np.square)\n",
    "true_fake_vec2 = pd.concat([true_fake_vec, vader_sent, lexicon_results, topic_dists], axis=1)\n",
    "\n",
    "# ss = StandardScaler()\n",
    "# true_fake_vec_all = ss.fit_transform(true_fake_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = pd.concat([truedfy, fakedfy], axis= 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(true_fake_vec, all_y, train_size=0.75, random_state=8)\n",
    "Xv_train, Xv_test, yv_train, yv_test = train_test_split(vader_sent, all_y,train_size=0.75, random_state=8)\n",
    "Xe_train, Xe_test, ye_train, ye_test = train_test_split(lexicon_results, all_y, train_size=0.75, random_state=8)\n",
    "Xlda_train, Xlda_test, ylda_train, ylda_test = train_test_split(topic_dists, all_y, train_size=0.75, random_state=8)\n",
    "Xa_train, Xa_test, ya_train, ya_test = train_test_split(true_fake_vec2, all_y,train_size=0.75, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def run_test(X, y, cv_val, scoring):\n",
    "    gnb = GaussianNB()\n",
    "    dtree = DecisionTreeClassifier()\n",
    "    svm2 = svm.SVC(random_state=8)\n",
    "    xg = XGBClassifier()\n",
    "    rf = RandomForestClassifier()\n",
    "    # logreg_cv = linear_model.LogisticRegressionCV(Cs=100, cv=5, penalty='l1',scoring='accuracy',solver='liblinear',n_jobs=-1)\n",
    "    print('Gaussian NB:')\n",
    "    scorelist = cross_val_score(gnb, X, y, cv=cv_val, scoring=scoring,n_jobs=-1)\n",
    "    print(scorelist, np.mean(scorelist))\n",
    "    print('DecisionTree')\n",
    "    scorelist = cross_val_score(dtree, X, y, cv=cv_val, scoring=scoring,n_jobs=-1)\n",
    "    print(scorelist, np.mean(scorelist))\n",
    "    print('Rand Forest:')\n",
    "    scorelist = cross_val_score(rf, X, y, cv=cv_val, scoring=scoring,n_jobs=-1)\n",
    "    print(scorelist, np.mean(scorelist))\n",
    "    print('SVM:')\n",
    "    scorelist = cross_val_score(svm2, X, y, cv=cv_val, scoring=scoring,n_jobs=-1)\n",
    "    print(scorelist, np.mean(scorelist))\n",
    "    print('XGB Default:')\n",
    "    scorelist = cross_val_score(xg, X, y, cv=cv_val, scoring=scoring,n_jobs=-1)\n",
    "    print(scorelist, np.mean(scorelist))\n",
    "    # print('Logistics Regression:')\n",
    "    # scorelist = cross_val_score(logreg_cv, X_train, y_train, cv=5, scoring='f1', n_jobs=-1)\n",
    "    # print(scorelist, np.mean(scorelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_test(Xe_train, ye_train, 5, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_test(Xv_train, yv_train, 5, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_test(X_train, y_train, 5, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_test(Xlda_train, ylda_train, 5, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB:\n",
      "[0.75576037 0.66981132 0.6695279  0.74774775 0.70422535] 0.7094145372548887\n",
      "DecisionTree\n",
      "[0.69527897 0.64253394 0.69019608 0.67226891 0.68595041] 0.6772456611652407\n",
      "Rand Forest:\n",
      "[0.69124424 0.63207547 0.67256637 0.60952381 0.68907563] 0.6588971045573553\n",
      "SVM:\n",
      "[0.77911647 0.70638298 0.71372549 0.72803347 0.72649573] 0.7307508268164021\n",
      "XGB Default:\n",
      "[0.87179487 0.77732794 0.82786885 0.78333333 0.82553191] 0.817171381540702\n"
     ]
    }
   ],
   "source": [
    "run_test(Xa_train, ya_train, 5, 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_clf = svm.SVC(random_state=8)\n",
    "# svm_params = {\n",
    "#     \"kernel\":['rbf','linear'],\n",
    "#     'C':[0.1,0.2,0.4,0.6,0.8,1,10],\n",
    "#     'gamma': np.logspace(-1,1,9)\n",
    "# }\n",
    "# scorer = make_scorer(fbeta_score,beta=0.5)\n",
    "# svm_gs = GridSearchCV(svm_clf, svm_params, cv=5, scoring=scorer, n_jobs=-1)\n",
    "# svm_gs.fit(Xa_train,ya_train)\n",
    "# best_clf = svm_gs.best_estimator_\n",
    "# print(best_clf)\n",
    "# best_pred = best_clf.predict(Xa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance = {'accuracy': accuracy_score(best_pred,y_test),\n",
    "#                 'recall': recall_score(best_pred,y_test),\n",
    "#                 'precision': precision_score(best_pred,y_test)}\n",
    "# print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.4,\n",
      "       gamma=0.05, learning_rate=0.1, max_delta_step=0, max_depth=20,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
      "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=0.7)\n"
     ]
    }
   ],
   "source": [
    "xg_clf = XGBClassifier()\n",
    "xg_params = {\n",
    "#     'booster'=['gbtree'],\n",
    "    'colsample_bytree':[0.15,0.4,0.85],\n",
    "    'max_depth':[4,8,16,20],\n",
    "    'subsample':[0.7,0.95],\n",
    "    'min_child_weight':[1,3,9],\n",
    "    'gamma':[0,0.01,0.05,0.3,0.6,1]\n",
    "}\n",
    "scorer = make_scorer(fbeta_score,beta=0.5)\n",
    "xg_gs = GridSearchCV(xg_clf, xg_params, cv=5, scoring=scorer, n_jobs=-1)\n",
    "xg_gs.fit(Xa_train,ya_train)\n",
    "best_xg_clf = xg_gs.best_estimator_\n",
    "print(best_xg_clf)\n",
    "best_pred = best_xg_clf.predict(Xa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.88, 'recall': 0.9065934065934066, 'precision': 0.8418367346938775}\n"
     ]
    }
   ],
   "source": [
    "performance = {'accuracy': accuracy_score(best_pred,y_test),\n",
    "                'recall': recall_score(best_pred,y_test),\n",
    "                'precision': precision_score(best_pred,y_test)}\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
